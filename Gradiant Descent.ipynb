{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0132ff00-6b8a-4150-aeeb-2de01adcee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99250f71-7c58-47f7-a38d-1756b464f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\soura\\Desktop\\csv files\\insurance_data_codebasics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c1265a-7223-495c-85ff-e5c17e10184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56724abe-5f1b-4da5-babb-1fd9df512975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb451ed-2336-4e5a-a237-260a0303d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df[[\"age\",\"affordibility\"]],df[\"bought_insurance\"],test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d69977-2523-4a14-ab38-15ea17385bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe5a582-8c22-42b6-8014-5a89bff84176",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=x_train.copy()\n",
    "x_train_scaled['age'] = x_train_scaled['age']/100\n",
    "\n",
    "x_test_scaled = x_test.copy()\n",
    "x_test_scaled['age']=x_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e733aec4-651c-4910-b542-5dbdb762ce46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0\n",
       "6   0.55              0\n",
       "17  0.58              1\n",
       "24  0.50              1\n",
       "19  0.18              1\n",
       "25  0.54              1\n",
       "16  0.25              0\n",
       "20  0.21              1\n",
       "3   0.52              0\n",
       "7   0.60              0\n",
       "1   0.25              0\n",
       "5   0.56              1\n",
       "27  0.46              1\n",
       "8   0.62              1\n",
       "18  0.19              0\n",
       "12  0.27              0\n",
       "23  0.45              1\n",
       "22  0.40              1\n",
       "15  0.55              1\n",
       "26  0.23              1\n",
       "4   0.46              1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4214a155-115b-4bcb-a5fb-9e5975dbf129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7110 - accuracy: 0.5000\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7106 - accuracy: 0.5000\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7102 - accuracy: 0.5000\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7098 - accuracy: 0.5000\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7094 - accuracy: 0.5000\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7091 - accuracy: 0.5000\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7087 - accuracy: 0.5000\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7083 - accuracy: 0.5000\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7079 - accuracy: 0.5000\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7076 - accuracy: 0.5000\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7072 - accuracy: 0.5000\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7068 - accuracy: 0.5000\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7065 - accuracy: 0.5000\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7061 - accuracy: 0.5000\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7057 - accuracy: 0.5000\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7054 - accuracy: 0.5000\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7050 - accuracy: 0.5000\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7046 - accuracy: 0.5000\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7039 - accuracy: 0.5000\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7035 - accuracy: 0.5000\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7032 - accuracy: 0.5000\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7028 - accuracy: 0.5000\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7021 - accuracy: 0.5000\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7017 - accuracy: 0.5000\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7010 - accuracy: 0.5000\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7007 - accuracy: 0.5000\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6996 - accuracy: 0.5000\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6993 - accuracy: 0.5000\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6989 - accuracy: 0.5000\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6972 - accuracy: 0.5000\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6962 - accuracy: 0.5000\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6958 - accuracy: 0.5000\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6952 - accuracy: 0.5000\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6942 - accuracy: 0.5000\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6922 - accuracy: 0.5000\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6918 - accuracy: 0.5000\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6912 - accuracy: 0.5000\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 60/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6902 - accuracy: 0.5000\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6899 - accuracy: 0.5000\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6896 - accuracy: 0.5000\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6893 - accuracy: 0.5000\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6890 - accuracy: 0.5000\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6886 - accuracy: 0.5000\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6883 - accuracy: 0.5000\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6877 - accuracy: 0.5000\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6874 - accuracy: 0.5000\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6871 - accuracy: 0.5000\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6868 - accuracy: 0.5000\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6865 - accuracy: 0.5000\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6862 - accuracy: 0.5000\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6859 - accuracy: 0.5000\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6856 - accuracy: 0.5000\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6853 - accuracy: 0.5000\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6846 - accuracy: 0.5000\n",
      "Epoch 80/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6843 - accuracy: 0.5000\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6840 - accuracy: 0.5000\n",
      "Epoch 82/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6838 - accuracy: 0.5000\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6835 - accuracy: 0.5000\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6832 - accuracy: 0.5000\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6826 - accuracy: 0.5000\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6823 - accuracy: 0.5000\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6820 - accuracy: 0.5000\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6817 - accuracy: 0.5000\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6814 - accuracy: 0.5000\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6811 - accuracy: 0.5000\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6808 - accuracy: 0.5000\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6805 - accuracy: 0.5000\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6803 - accuracy: 0.5000\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6800 - accuracy: 0.5000\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6797 - accuracy: 0.5000\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6794 - accuracy: 0.5000\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6791 - accuracy: 0.5000\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6788 - accuracy: 0.5000\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6786 - accuracy: 0.5000\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6783 - accuracy: 0.5000\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6780 - accuracy: 0.5000\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6777 - accuracy: 0.5000\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6775 - accuracy: 0.5000\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6772 - accuracy: 0.5000\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6769 - accuracy: 0.5000\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6766 - accuracy: 0.5000\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6764 - accuracy: 0.5000\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6761 - accuracy: 0.5000\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6758 - accuracy: 0.5000\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6756 - accuracy: 0.5000\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6753 - accuracy: 0.5000\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6750 - accuracy: 0.5000\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6748 - accuracy: 0.5000\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6745 - accuracy: 0.5000\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6742 - accuracy: 0.5000\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6740 - accuracy: 0.5000\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6737 - accuracy: 0.5000\n",
      "Epoch 119/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6735 - accuracy: 0.5000\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6732 - accuracy: 0.5000\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6730 - accuracy: 0.5000\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6727 - accuracy: 0.5000\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6724 - accuracy: 0.5000\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6722 - accuracy: 0.5000\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6719 - accuracy: 0.5000\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6717 - accuracy: 0.5000\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6714 - accuracy: 0.5000\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6712 - accuracy: 0.5000\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6709 - accuracy: 0.5000\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6707 - accuracy: 0.5000\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6704 - accuracy: 0.5000\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6702 - accuracy: 0.5000\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6699 - accuracy: 0.5000\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6697 - accuracy: 0.5000\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6695 - accuracy: 0.5000\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6692 - accuracy: 0.5000\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6690 - accuracy: 0.5000\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6687 - accuracy: 0.5000\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6685 - accuracy: 0.5000\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6683 - accuracy: 0.5000\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6680 - accuracy: 0.5000\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6678 - accuracy: 0.5000\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6675 - accuracy: 0.5000\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6673 - accuracy: 0.5000\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6671 - accuracy: 0.5000\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6668 - accuracy: 0.5000\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6666 - accuracy: 0.5000\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6664 - accuracy: 0.5000\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6661 - accuracy: 0.5000\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6659 - accuracy: 0.5000\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6657 - accuracy: 0.5000\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6655 - accuracy: 0.5000\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6652 - accuracy: 0.5000\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6650 - accuracy: 0.5000\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6648 - accuracy: 0.5000\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6646 - accuracy: 0.5000\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6643 - accuracy: 0.5000\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6641 - accuracy: 0.5000\n",
      "Epoch 159/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6639 - accuracy: 0.5000\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6637 - accuracy: 0.5000\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6635 - accuracy: 0.5000\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6632 - accuracy: 0.5000\n",
      "Epoch 163/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6630 - accuracy: 0.5000\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 165/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6626 - accuracy: 0.5000\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6624 - accuracy: 0.5000\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6622 - accuracy: 0.5000\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6620 - accuracy: 0.5000\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6613 - accuracy: 0.5000\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6611 - accuracy: 0.5000\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6609 - accuracy: 0.5455\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6607 - accuracy: 0.5455\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6605 - accuracy: 0.5455\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6603 - accuracy: 0.5455\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6601 - accuracy: 0.5455\n",
      "Epoch 178/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6599 - accuracy: 0.5455\n",
      "Epoch 179/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6597 - accuracy: 0.5455\n",
      "Epoch 180/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6595 - accuracy: 0.5455\n",
      "Epoch 181/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6593 - accuracy: 0.5455\n",
      "Epoch 182/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6591 - accuracy: 0.5455\n",
      "Epoch 183/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6589 - accuracy: 0.5455\n",
      "Epoch 184/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6587 - accuracy: 0.5455\n",
      "Epoch 185/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6585 - accuracy: 0.5455\n",
      "Epoch 186/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6583 - accuracy: 0.5455\n",
      "Epoch 187/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6581 - accuracy: 0.5455\n",
      "Epoch 188/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6579 - accuracy: 0.5455\n",
      "Epoch 189/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6577 - accuracy: 0.5455\n",
      "Epoch 190/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6575 - accuracy: 0.5455\n",
      "Epoch 191/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6573 - accuracy: 0.5455\n",
      "Epoch 192/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6571 - accuracy: 0.5455\n",
      "Epoch 193/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6569 - accuracy: 0.5455\n",
      "Epoch 194/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6568 - accuracy: 0.5455\n",
      "Epoch 195/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6566 - accuracy: 0.5455\n",
      "Epoch 196/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6564 - accuracy: 0.5455\n",
      "Epoch 197/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6562 - accuracy: 0.5455\n",
      "Epoch 198/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6560 - accuracy: 0.5455\n",
      "Epoch 199/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6558 - accuracy: 0.5455\n",
      "Epoch 200/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6556 - accuracy: 0.5455\n",
      "Epoch 201/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6555 - accuracy: 0.5455\n",
      "Epoch 202/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6553 - accuracy: 0.5455\n",
      "Epoch 203/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6551 - accuracy: 0.5455\n",
      "Epoch 204/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6549 - accuracy: 0.5455\n",
      "Epoch 205/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6547 - accuracy: 0.5455\n",
      "Epoch 206/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6545 - accuracy: 0.5455\n",
      "Epoch 207/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6544 - accuracy: 0.5455\n",
      "Epoch 208/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6542 - accuracy: 0.5455\n",
      "Epoch 209/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6540 - accuracy: 0.5455\n",
      "Epoch 210/5000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6538 - accuracy: 0.5455\n",
      "Epoch 211/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6537 - accuracy: 0.5455\n",
      "Epoch 212/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6535 - accuracy: 0.5455\n",
      "Epoch 213/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6533 - accuracy: 0.5455\n",
      "Epoch 214/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6531 - accuracy: 0.5455\n",
      "Epoch 215/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6530 - accuracy: 0.5455\n",
      "Epoch 216/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6528 - accuracy: 0.5455\n",
      "Epoch 217/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6526 - accuracy: 0.5455\n",
      "Epoch 218/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6525 - accuracy: 0.5455\n",
      "Epoch 219/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6523 - accuracy: 0.5455\n",
      "Epoch 220/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6521 - accuracy: 0.5455\n",
      "Epoch 221/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6519 - accuracy: 0.5455\n",
      "Epoch 222/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6518 - accuracy: 0.5455\n",
      "Epoch 223/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6516 - accuracy: 0.5455\n",
      "Epoch 224/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6515 - accuracy: 0.5455\n",
      "Epoch 225/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6513 - accuracy: 0.5455\n",
      "Epoch 226/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6511 - accuracy: 0.5455\n",
      "Epoch 227/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6510 - accuracy: 0.5455\n",
      "Epoch 228/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6508 - accuracy: 0.5455\n",
      "Epoch 229/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6506 - accuracy: 0.5455\n",
      "Epoch 230/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6505 - accuracy: 0.5455\n",
      "Epoch 231/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6503 - accuracy: 0.5455\n",
      "Epoch 232/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6502 - accuracy: 0.5455\n",
      "Epoch 233/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6500 - accuracy: 0.5455\n",
      "Epoch 234/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6498 - accuracy: 0.5455\n",
      "Epoch 235/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6497 - accuracy: 0.5455\n",
      "Epoch 236/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6495 - accuracy: 0.5455\n",
      "Epoch 237/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6494 - accuracy: 0.5455\n",
      "Epoch 238/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6492 - accuracy: 0.5455\n",
      "Epoch 239/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6491 - accuracy: 0.5455\n",
      "Epoch 240/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6489 - accuracy: 0.5455\n",
      "Epoch 241/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6488 - accuracy: 0.5455\n",
      "Epoch 242/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6486 - accuracy: 0.5909\n",
      "Epoch 243/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6485 - accuracy: 0.5909\n",
      "Epoch 244/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6483 - accuracy: 0.5909\n",
      "Epoch 245/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6482 - accuracy: 0.5909\n",
      "Epoch 246/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6480 - accuracy: 0.5909\n",
      "Epoch 247/5000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6479 - accuracy: 0.5909\n",
      "Epoch 248/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6477 - accuracy: 0.5909\n",
      "Epoch 249/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6476 - accuracy: 0.5909\n",
      "Epoch 250/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6474 - accuracy: 0.5909\n",
      "Epoch 251/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6473 - accuracy: 0.5909\n",
      "Epoch 252/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6471 - accuracy: 0.5909\n",
      "Epoch 253/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6470 - accuracy: 0.5909\n",
      "Epoch 254/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6468 - accuracy: 0.5909\n",
      "Epoch 255/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6467 - accuracy: 0.5909\n",
      "Epoch 256/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6465 - accuracy: 0.5909\n",
      "Epoch 257/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6464 - accuracy: 0.5909\n",
      "Epoch 258/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6463 - accuracy: 0.5909\n",
      "Epoch 259/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6461 - accuracy: 0.6364\n",
      "Epoch 260/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6460 - accuracy: 0.6364\n",
      "Epoch 261/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6458 - accuracy: 0.6364\n",
      "Epoch 262/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6457 - accuracy: 0.6364\n",
      "Epoch 263/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6456 - accuracy: 0.6364\n",
      "Epoch 264/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6454 - accuracy: 0.6364\n",
      "Epoch 265/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6453 - accuracy: 0.6364\n",
      "Epoch 266/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6452 - accuracy: 0.6364\n",
      "Epoch 267/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6450 - accuracy: 0.6364\n",
      "Epoch 268/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6449 - accuracy: 0.6364\n",
      "Epoch 269/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6448 - accuracy: 0.6364\n",
      "Epoch 270/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6446 - accuracy: 0.6364\n",
      "Epoch 271/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6445 - accuracy: 0.6364\n",
      "Epoch 272/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6444 - accuracy: 0.6364\n",
      "Epoch 273/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6442 - accuracy: 0.6364\n",
      "Epoch 274/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6441 - accuracy: 0.6364\n",
      "Epoch 275/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6440 - accuracy: 0.6364\n",
      "Epoch 276/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6438 - accuracy: 0.6364\n",
      "Epoch 277/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6437 - accuracy: 0.6364\n",
      "Epoch 278/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6436 - accuracy: 0.6364\n",
      "Epoch 279/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6435 - accuracy: 0.6364\n",
      "Epoch 280/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6433 - accuracy: 0.6364\n",
      "Epoch 281/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6432 - accuracy: 0.6364\n",
      "Epoch 282/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6431 - accuracy: 0.6364\n",
      "Epoch 283/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6430 - accuracy: 0.6364\n",
      "Epoch 284/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6428 - accuracy: 0.6364\n",
      "Epoch 285/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6427 - accuracy: 0.6364\n",
      "Epoch 286/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6426 - accuracy: 0.6364\n",
      "Epoch 287/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6425 - accuracy: 0.6364\n",
      "Epoch 288/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6423 - accuracy: 0.6364\n",
      "Epoch 289/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6422 - accuracy: 0.6364\n",
      "Epoch 290/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6421 - accuracy: 0.6364\n",
      "Epoch 291/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6420 - accuracy: 0.6364\n",
      "Epoch 292/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6419 - accuracy: 0.6364\n",
      "Epoch 293/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6417 - accuracy: 0.6364\n",
      "Epoch 294/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6416 - accuracy: 0.6364\n",
      "Epoch 295/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6415 - accuracy: 0.6364\n",
      "Epoch 296/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6414 - accuracy: 0.6364\n",
      "Epoch 297/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6413 - accuracy: 0.6364\n",
      "Epoch 298/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6411 - accuracy: 0.6364\n",
      "Epoch 299/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6410 - accuracy: 0.6364\n",
      "Epoch 300/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6409 - accuracy: 0.6364\n",
      "Epoch 301/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6408 - accuracy: 0.6364\n",
      "Epoch 302/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6407 - accuracy: 0.6364\n",
      "Epoch 303/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6406 - accuracy: 0.6364\n",
      "Epoch 304/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6405 - accuracy: 0.6364\n",
      "Epoch 305/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6403 - accuracy: 0.6364\n",
      "Epoch 306/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6402 - accuracy: 0.6364\n",
      "Epoch 307/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6401 - accuracy: 0.6364\n",
      "Epoch 308/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6400 - accuracy: 0.6364\n",
      "Epoch 309/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6399 - accuracy: 0.6364\n",
      "Epoch 310/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6398 - accuracy: 0.6364\n",
      "Epoch 311/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6397 - accuracy: 0.6364\n",
      "Epoch 312/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6396 - accuracy: 0.6364\n",
      "Epoch 313/5000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6395 - accuracy: 0.6364\n",
      "Epoch 314/5000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6394 - accuracy: 0.6364\n",
      "Epoch 315/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6392 - accuracy: 0.6364\n",
      "Epoch 316/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6391 - accuracy: 0.6364\n",
      "Epoch 317/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6390 - accuracy: 0.6364\n",
      "Epoch 318/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6389 - accuracy: 0.6364\n",
      "Epoch 319/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6388 - accuracy: 0.6364\n",
      "Epoch 320/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6387 - accuracy: 0.6364\n",
      "Epoch 321/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6386 - accuracy: 0.6364\n",
      "Epoch 322/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6385 - accuracy: 0.6364\n",
      "Epoch 323/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6384 - accuracy: 0.6364\n",
      "Epoch 324/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6383 - accuracy: 0.6364\n",
      "Epoch 325/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6382 - accuracy: 0.6364\n",
      "Epoch 326/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6381 - accuracy: 0.6364\n",
      "Epoch 327/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6380 - accuracy: 0.6364\n",
      "Epoch 328/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6379 - accuracy: 0.6364\n",
      "Epoch 329/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6378 - accuracy: 0.6364\n",
      "Epoch 330/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6377 - accuracy: 0.6364\n",
      "Epoch 331/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6376 - accuracy: 0.6364\n",
      "Epoch 332/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6375 - accuracy: 0.6364\n",
      "Epoch 333/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6374 - accuracy: 0.6364\n",
      "Epoch 334/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6373 - accuracy: 0.6364\n",
      "Epoch 335/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6372 - accuracy: 0.6364\n",
      "Epoch 336/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6371 - accuracy: 0.6364\n",
      "Epoch 337/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6370 - accuracy: 0.6364\n",
      "Epoch 338/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6369 - accuracy: 0.6364\n",
      "Epoch 339/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6368 - accuracy: 0.6364\n",
      "Epoch 340/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6367 - accuracy: 0.6364\n",
      "Epoch 341/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6366 - accuracy: 0.6364\n",
      "Epoch 342/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6365 - accuracy: 0.6364\n",
      "Epoch 343/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6364 - accuracy: 0.6364\n",
      "Epoch 344/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6363 - accuracy: 0.6364\n",
      "Epoch 345/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6362 - accuracy: 0.6364\n",
      "Epoch 346/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 347/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6361 - accuracy: 0.6364\n",
      "Epoch 348/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6360 - accuracy: 0.6364\n",
      "Epoch 349/5000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6359 - accuracy: 0.6364\n",
      "Epoch 350/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6358 - accuracy: 0.6364\n",
      "Epoch 351/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6357 - accuracy: 0.6364\n",
      "Epoch 352/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6356 - accuracy: 0.6364\n",
      "Epoch 353/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6355 - accuracy: 0.6364\n",
      "Epoch 354/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6354 - accuracy: 0.6364\n",
      "Epoch 355/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6353 - accuracy: 0.6364\n",
      "Epoch 356/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6352 - accuracy: 0.6364\n",
      "Epoch 357/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6352 - accuracy: 0.6364\n",
      "Epoch 358/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6351 - accuracy: 0.6364\n",
      "Epoch 359/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6350 - accuracy: 0.6364\n",
      "Epoch 360/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6349 - accuracy: 0.6364\n",
      "Epoch 361/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6348 - accuracy: 0.6364\n",
      "Epoch 362/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6347 - accuracy: 0.6364\n",
      "Epoch 363/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6346 - accuracy: 0.6364\n",
      "Epoch 364/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6345 - accuracy: 0.6364\n",
      "Epoch 365/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6345 - accuracy: 0.6364\n",
      "Epoch 366/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6344 - accuracy: 0.6364\n",
      "Epoch 367/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6343 - accuracy: 0.6364\n",
      "Epoch 368/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6342 - accuracy: 0.6364\n",
      "Epoch 369/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6341 - accuracy: 0.6364\n",
      "Epoch 370/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6340 - accuracy: 0.6364\n",
      "Epoch 371/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6339 - accuracy: 0.6364\n",
      "Epoch 372/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6339 - accuracy: 0.6364\n",
      "Epoch 373/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6338 - accuracy: 0.6364\n",
      "Epoch 374/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6337 - accuracy: 0.6364\n",
      "Epoch 375/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6336 - accuracy: 0.6364\n",
      "Epoch 376/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6335 - accuracy: 0.6364\n",
      "Epoch 377/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6335 - accuracy: 0.6364\n",
      "Epoch 378/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6334 - accuracy: 0.6364\n",
      "Epoch 379/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6333 - accuracy: 0.6364\n",
      "Epoch 380/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6332 - accuracy: 0.6364\n",
      "Epoch 381/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6331 - accuracy: 0.6364\n",
      "Epoch 382/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6331 - accuracy: 0.6364\n",
      "Epoch 383/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6330 - accuracy: 0.6364\n",
      "Epoch 384/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6329 - accuracy: 0.6364\n",
      "Epoch 385/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6328 - accuracy: 0.6364\n",
      "Epoch 386/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6327 - accuracy: 0.6364\n",
      "Epoch 387/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6327 - accuracy: 0.6364\n",
      "Epoch 388/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6326 - accuracy: 0.6364\n",
      "Epoch 389/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6325 - accuracy: 0.6364\n",
      "Epoch 390/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6324 - accuracy: 0.6364\n",
      "Epoch 391/5000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 392/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6323 - accuracy: 0.6364\n",
      "Epoch 393/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6322 - accuracy: 0.6364\n",
      "Epoch 394/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6321 - accuracy: 0.6364\n",
      "Epoch 395/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 396/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6320 - accuracy: 0.6364\n",
      "Epoch 397/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.6364\n",
      "Epoch 398/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6318 - accuracy: 0.6364\n",
      "Epoch 399/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 400/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 401/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6316 - accuracy: 0.6364\n",
      "Epoch 402/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 403/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 404/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 405/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 406/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 407/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 408/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6311 - accuracy: 0.6364\n",
      "Epoch 409/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 410/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 411/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 412/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6308 - accuracy: 0.6364\n",
      "Epoch 413/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 414/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 415/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6306 - accuracy: 0.6364\n",
      "Epoch 416/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 417/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 418/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 419/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6303 - accuracy: 0.6364\n",
      "Epoch 420/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 421/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 422/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 423/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 424/5000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 425/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 426/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 427/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 428/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6297 - accuracy: 0.6364\n",
      "Epoch 429/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 430/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 431/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 432/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6294 - accuracy: 0.6364\n",
      "Epoch 433/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6294 - accuracy: 0.6364\n",
      "Epoch 434/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6293 - accuracy: 0.6364\n",
      "Epoch 435/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 436/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6292 - accuracy: 0.6364\n",
      "Epoch 437/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6291 - accuracy: 0.6364\n",
      "Epoch 438/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6290 - accuracy: 0.6364\n",
      "Epoch 439/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6290 - accuracy: 0.6364\n",
      "Epoch 440/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6289 - accuracy: 0.6364\n",
      "Epoch 441/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 442/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6288 - accuracy: 0.6364\n",
      "Epoch 443/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 444/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6287 - accuracy: 0.6364\n",
      "Epoch 445/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6286 - accuracy: 0.6364\n",
      "Epoch 446/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6285 - accuracy: 0.6364\n",
      "Epoch 447/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6285 - accuracy: 0.6364\n",
      "Epoch 448/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6284 - accuracy: 0.6364\n",
      "Epoch 449/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 450/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6283 - accuracy: 0.6364\n",
      "Epoch 451/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 452/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6282 - accuracy: 0.6364\n",
      "Epoch 453/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6281 - accuracy: 0.6364\n",
      "Epoch 454/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6280 - accuracy: 0.6364\n",
      "Epoch 455/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6280 - accuracy: 0.6364\n",
      "Epoch 456/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6279 - accuracy: 0.6364\n",
      "Epoch 457/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 458/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6278 - accuracy: 0.6364\n",
      "Epoch 459/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 460/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6277 - accuracy: 0.6364\n",
      "Epoch 461/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6276 - accuracy: 0.6364\n",
      "Epoch 462/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 463/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6275 - accuracy: 0.6364\n",
      "Epoch 464/5000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6274 - accuracy: 0.6364\n",
      "Epoch 465/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6274 - accuracy: 0.6364\n",
      "Epoch 466/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6273 - accuracy: 0.6364\n",
      "Epoch 467/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 468/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6272 - accuracy: 0.6364\n",
      "Epoch 469/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 470/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6271 - accuracy: 0.6364\n",
      "Epoch 471/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6270 - accuracy: 0.6364\n",
      "Epoch 472/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 473/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6269 - accuracy: 0.6364\n",
      "Epoch 474/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 475/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6268 - accuracy: 0.6364\n",
      "Epoch 476/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 477/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6267 - accuracy: 0.6364\n",
      "Epoch 478/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6266 - accuracy: 0.6364\n",
      "Epoch 479/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 480/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6265 - accuracy: 0.6364\n",
      "Epoch 481/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 482/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6264 - accuracy: 0.6364\n",
      "Epoch 483/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6263 - accuracy: 0.6364\n",
      "Epoch 484/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 485/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6262 - accuracy: 0.6364\n",
      "Epoch 486/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 487/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6261 - accuracy: 0.6364\n",
      "Epoch 488/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 489/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6260 - accuracy: 0.6364\n",
      "Epoch 490/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 491/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6259 - accuracy: 0.6364\n",
      "Epoch 492/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6258 - accuracy: 0.6364\n",
      "Epoch 493/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 494/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6257 - accuracy: 0.6364\n",
      "Epoch 495/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 496/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6256 - accuracy: 0.6364\n",
      "Epoch 497/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1758/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1759/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1760/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5636 - accuracy: 0.6818\n",
      "Epoch 1761/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5636 - accuracy: 0.6818\n",
      "Epoch 1762/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5635 - accuracy: 0.6818\n",
      "Epoch 1763/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5635 - accuracy: 0.6818\n",
      "Epoch 1764/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5634 - accuracy: 0.6818\n",
      "Epoch 1765/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5634 - accuracy: 0.6818\n",
      "Epoch 1766/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5633 - accuracy: 0.6818\n",
      "Epoch 1767/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5633 - accuracy: 0.6818\n",
      "Epoch 1768/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5632 - accuracy: 0.6818\n",
      "Epoch 1769/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5632 - accuracy: 0.6818\n",
      "Epoch 1770/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5631 - accuracy: 0.6818\n",
      "Epoch 1771/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5631 - accuracy: 0.6818\n",
      "Epoch 1772/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5631 - accuracy: 0.6818\n",
      "Epoch 1773/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5630 - accuracy: 0.6818\n",
      "Epoch 1774/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5630 - accuracy: 0.6818\n",
      "Epoch 1775/5000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5629 - accuracy: 0.6818\n",
      "Epoch 1776/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5629 - accuracy: 0.6818\n",
      "Epoch 1777/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5628 - accuracy: 0.6818\n",
      "Epoch 1778/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5628 - accuracy: 0.6818\n",
      "Epoch 1779/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5627 - accuracy: 0.6818\n",
      "Epoch 1780/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5627 - accuracy: 0.6818\n",
      "Epoch 1781/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5626 - accuracy: 0.6818\n",
      "Epoch 1782/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5626 - accuracy: 0.6818\n",
      "Epoch 1783/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5625 - accuracy: 0.6818\n",
      "Epoch 1784/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5625 - accuracy: 0.6818\n",
      "Epoch 1785/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5625 - accuracy: 0.6818\n",
      "Epoch 1786/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5624 - accuracy: 0.6818\n",
      "Epoch 1787/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5624 - accuracy: 0.6818\n",
      "Epoch 1788/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5623 - accuracy: 0.6818\n",
      "Epoch 1789/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5623 - accuracy: 0.6818\n",
      "Epoch 1790/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5622 - accuracy: 0.6818\n",
      "Epoch 1791/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5622 - accuracy: 0.6818\n",
      "Epoch 1792/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5621 - accuracy: 0.6818\n",
      "Epoch 1793/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5621 - accuracy: 0.6818\n",
      "Epoch 1794/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5620 - accuracy: 0.6818\n",
      "Epoch 1795/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5620 - accuracy: 0.6818\n",
      "Epoch 1796/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5619 - accuracy: 0.6818\n",
      "Epoch 1797/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5619 - accuracy: 0.6818\n",
      "Epoch 1798/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5619 - accuracy: 0.6818\n",
      "Epoch 1799/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5618 - accuracy: 0.6818\n",
      "Epoch 1800/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5618 - accuracy: 0.6818\n",
      "Epoch 1801/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5617 - accuracy: 0.6818\n",
      "Epoch 1802/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5617 - accuracy: 0.6818\n",
      "Epoch 1803/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5616 - accuracy: 0.6818\n",
      "Epoch 1804/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5616 - accuracy: 0.6818\n",
      "Epoch 1805/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5615 - accuracy: 0.6818\n",
      "Epoch 1806/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5615 - accuracy: 0.6818\n",
      "Epoch 1807/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5614 - accuracy: 0.6818\n",
      "Epoch 1808/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5614 - accuracy: 0.6818\n",
      "Epoch 1809/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5614 - accuracy: 0.6818\n",
      "Epoch 1810/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5613 - accuracy: 0.6818\n",
      "Epoch 1811/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5613 - accuracy: 0.6818\n",
      "Epoch 1812/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5612 - accuracy: 0.6818\n",
      "Epoch 1813/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5612 - accuracy: 0.6818\n",
      "Epoch 1814/5000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5611 - accuracy: 0.6818\n",
      "Epoch 1815/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5611 - accuracy: 0.6818\n",
      "Epoch 1816/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5610 - accuracy: 0.6818\n",
      "Epoch 1817/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5610 - accuracy: 0.6818\n",
      "Epoch 1818/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5609 - accuracy: 0.6818\n",
      "Epoch 1819/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5609 - accuracy: 0.6818\n",
      "Epoch 1820/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5609 - accuracy: 0.6818\n",
      "Epoch 1821/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5608 - accuracy: 0.6818\n",
      "Epoch 1822/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5608 - accuracy: 0.6818\n",
      "Epoch 1823/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5607 - accuracy: 0.6818\n",
      "Epoch 1824/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5607 - accuracy: 0.6818\n",
      "Epoch 1825/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5606 - accuracy: 0.6818\n",
      "Epoch 1826/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5606 - accuracy: 0.6818\n",
      "Epoch 1827/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5605 - accuracy: 0.6818\n",
      "Epoch 1828/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5605 - accuracy: 0.6818\n",
      "Epoch 1829/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 1830/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 1831/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 1832/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5603 - accuracy: 0.6818\n",
      "Epoch 1833/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5603 - accuracy: 0.6818\n",
      "Epoch 1834/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5602 - accuracy: 0.6818\n",
      "Epoch 1835/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5602 - accuracy: 0.6818\n",
      "Epoch 1836/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5601 - accuracy: 0.6818\n",
      "Epoch 1837/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5601 - accuracy: 0.6818\n",
      "Epoch 1838/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5600 - accuracy: 0.6818\n",
      "Epoch 1839/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5600 - accuracy: 0.6818\n",
      "Epoch 1840/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5599 - accuracy: 0.6818\n",
      "Epoch 1841/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5599 - accuracy: 0.6818\n",
      "Epoch 1842/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5599 - accuracy: 0.6818\n",
      "Epoch 1843/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5598 - accuracy: 0.6818\n",
      "Epoch 1844/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5598 - accuracy: 0.6818\n",
      "Epoch 1845/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5597 - accuracy: 0.6818\n",
      "Epoch 1846/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5597 - accuracy: 0.6818\n",
      "Epoch 1847/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5596 - accuracy: 0.6818\n",
      "Epoch 1848/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5596 - accuracy: 0.6818\n",
      "Epoch 1849/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5595 - accuracy: 0.6818\n",
      "Epoch 1850/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5595 - accuracy: 0.6818\n",
      "Epoch 1851/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 1852/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 1853/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 1854/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5593 - accuracy: 0.6818\n",
      "Epoch 1855/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5593 - accuracy: 0.6818\n",
      "Epoch 1856/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5592 - accuracy: 0.6818\n",
      "Epoch 1857/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5592 - accuracy: 0.6818\n",
      "Epoch 1858/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5591 - accuracy: 0.6818\n",
      "Epoch 1859/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5591 - accuracy: 0.6818\n",
      "Epoch 1860/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5590 - accuracy: 0.6818\n",
      "Epoch 1861/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5590 - accuracy: 0.6818\n",
      "Epoch 1862/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5589 - accuracy: 0.6818\n",
      "Epoch 1863/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5589 - accuracy: 0.6818\n",
      "Epoch 1864/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5589 - accuracy: 0.6818\n",
      "Epoch 1865/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5588 - accuracy: 0.6818\n",
      "Epoch 1866/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5588 - accuracy: 0.6818\n",
      "Epoch 1867/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5587 - accuracy: 0.6818\n",
      "Epoch 1868/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5587 - accuracy: 0.6818\n",
      "Epoch 1869/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5586 - accuracy: 0.6818\n",
      "Epoch 1870/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5586 - accuracy: 0.6818\n",
      "Epoch 1871/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5585 - accuracy: 0.6818\n",
      "Epoch 1872/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5585 - accuracy: 0.6818\n",
      "Epoch 1873/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 1874/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 1875/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 1876/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5583 - accuracy: 0.6818\n",
      "Epoch 1877/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5583 - accuracy: 0.6818\n",
      "Epoch 1878/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5582 - accuracy: 0.6818\n",
      "Epoch 1879/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5582 - accuracy: 0.6818\n",
      "Epoch 1880/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5581 - accuracy: 0.6818\n",
      "Epoch 1881/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5581 - accuracy: 0.6818\n",
      "Epoch 1882/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5580 - accuracy: 0.6818\n",
      "Epoch 1883/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5580 - accuracy: 0.6818\n",
      "Epoch 1884/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5580 - accuracy: 0.6818\n",
      "Epoch 1885/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5579 - accuracy: 0.6818\n",
      "Epoch 1886/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5579 - accuracy: 0.6818\n",
      "Epoch 1887/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5578 - accuracy: 0.6818\n",
      "Epoch 1888/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5578 - accuracy: 0.6818\n",
      "Epoch 1889/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5577 - accuracy: 0.6818\n",
      "Epoch 1890/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5577 - accuracy: 0.6818\n",
      "Epoch 1891/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5576 - accuracy: 0.6818\n",
      "Epoch 1892/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5576 - accuracy: 0.6818\n",
      "Epoch 1893/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 1894/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 1895/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 1896/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5574 - accuracy: 0.6818\n",
      "Epoch 1897/5000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5574 - accuracy: 0.6818\n",
      "Epoch 1898/5000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5573 - accuracy: 0.6818\n",
      "Epoch 1899/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5573 - accuracy: 0.6818\n",
      "Epoch 1900/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5572 - accuracy: 0.6818\n",
      "Epoch 1901/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5572 - accuracy: 0.6818\n",
      "Epoch 1902/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5571 - accuracy: 0.6818\n",
      "Epoch 1903/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5571 - accuracy: 0.6818\n",
      "Epoch 1904/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5571 - accuracy: 0.6818\n",
      "Epoch 1905/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5570 - accuracy: 0.6818\n",
      "Epoch 1906/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5570 - accuracy: 0.6818\n",
      "Epoch 1907/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5569 - accuracy: 0.6818\n",
      "Epoch 1908/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5569 - accuracy: 0.6818\n",
      "Epoch 1909/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5568 - accuracy: 0.6818\n",
      "Epoch 1910/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5568 - accuracy: 0.6818\n",
      "Epoch 1911/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5567 - accuracy: 0.6818\n",
      "Epoch 1912/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5567 - accuracy: 0.6818\n",
      "Epoch 1913/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5567 - accuracy: 0.6818\n",
      "Epoch 1914/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5566 - accuracy: 0.6818\n",
      "Epoch 1915/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5566 - accuracy: 0.6818\n",
      "Epoch 1916/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5565 - accuracy: 0.6818\n",
      "Epoch 1917/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5565 - accuracy: 0.6818\n",
      "Epoch 1918/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5564 - accuracy: 0.6818\n",
      "Epoch 1919/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5564 - accuracy: 0.6818\n",
      "Epoch 1920/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 1921/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 1922/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 1923/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5562 - accuracy: 0.6818\n",
      "Epoch 1924/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5562 - accuracy: 0.6818\n",
      "Epoch 1925/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5561 - accuracy: 0.6818\n",
      "Epoch 1926/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5561 - accuracy: 0.6818\n",
      "Epoch 1927/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5560 - accuracy: 0.6818\n",
      "Epoch 1928/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5560 - accuracy: 0.6818\n",
      "Epoch 1929/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5559 - accuracy: 0.6818\n",
      "Epoch 1930/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5559 - accuracy: 0.6818\n",
      "Epoch 1931/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5558 - accuracy: 0.6818\n",
      "Epoch 1932/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5558 - accuracy: 0.6818\n",
      "Epoch 1933/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5558 - accuracy: 0.6818\n",
      "Epoch 1934/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5557 - accuracy: 0.6818\n",
      "Epoch 1935/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5557 - accuracy: 0.6818\n",
      "Epoch 1936/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5556 - accuracy: 0.6818\n",
      "Epoch 1937/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5556 - accuracy: 0.6818\n",
      "Epoch 1938/5000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5555 - accuracy: 0.6818\n",
      "Epoch 1939/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5555 - accuracy: 0.6818\n",
      "Epoch 1940/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 1941/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 1942/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 1943/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5553 - accuracy: 0.6818\n",
      "Epoch 1944/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5553 - accuracy: 0.6818\n",
      "Epoch 1945/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5552 - accuracy: 0.6818\n",
      "Epoch 1946/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5552 - accuracy: 0.6818\n",
      "Epoch 1947/5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 1948/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 1949/5000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 1950/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5550 - accuracy: 0.6818\n",
      "Epoch 1951/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5550 - accuracy: 0.6818\n",
      "Epoch 1952/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5549 - accuracy: 0.6818\n",
      "Epoch 1953/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5549 - accuracy: 0.6818\n",
      "Epoch 1954/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5548 - accuracy: 0.6818\n",
      "Epoch 1955/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5548 - accuracy: 0.6818\n",
      "Epoch 1956/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5547 - accuracy: 0.6818\n",
      "Epoch 1957/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5547 - accuracy: 0.6818\n",
      "Epoch 1958/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5547 - accuracy: 0.6818\n",
      "Epoch 1959/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5546 - accuracy: 0.6818\n",
      "Epoch 1960/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5546 - accuracy: 0.6818\n",
      "Epoch 1961/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5545 - accuracy: 0.6818\n",
      "Epoch 1962/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5545 - accuracy: 0.6818\n",
      "Epoch 1963/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5544 - accuracy: 0.6818\n",
      "Epoch 1964/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5544 - accuracy: 0.6818\n",
      "Epoch 1965/5000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5543 - accuracy: 0.6818\n",
      "Epoch 1966/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5543 - accuracy: 0.6818\n",
      "Epoch 1967/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5543 - accuracy: 0.6818\n",
      "Epoch 1968/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5542 - accuracy: 0.6818\n",
      "Epoch 1969/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5542 - accuracy: 0.6818\n",
      "Epoch 1970/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5541 - accuracy: 0.6818\n",
      "Epoch 1971/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5541 - accuracy: 0.6818\n",
      "Epoch 1972/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5540 - accuracy: 0.6818\n",
      "Epoch 1973/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5540 - accuracy: 0.6818\n",
      "Epoch 1974/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5539 - accuracy: 0.6818\n",
      "Epoch 1975/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5539 - accuracy: 0.6818\n",
      "Epoch 1976/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5539 - accuracy: 0.6818\n",
      "Epoch 1977/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5538 - accuracy: 0.6818\n",
      "Epoch 1978/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5538 - accuracy: 0.6818\n",
      "Epoch 1979/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5537 - accuracy: 0.6818\n",
      "Epoch 1980/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5537 - accuracy: 0.6818\n",
      "Epoch 1981/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5536 - accuracy: 0.6818\n",
      "Epoch 1982/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5536 - accuracy: 0.6818\n",
      "Epoch 1983/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5535 - accuracy: 0.6818\n",
      "Epoch 1984/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5535 - accuracy: 0.6818\n",
      "Epoch 1985/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5535 - accuracy: 0.6818\n",
      "Epoch 1986/5000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5534 - accuracy: 0.6818\n",
      "Epoch 1987/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5534 - accuracy: 0.6818\n",
      "Epoch 1988/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5533 - accuracy: 0.6818\n",
      "Epoch 1989/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5533 - accuracy: 0.6818\n",
      "Epoch 1990/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5532 - accuracy: 0.6818\n",
      "Epoch 1991/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5532 - accuracy: 0.6818\n",
      "Epoch 1992/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5532 - accuracy: 0.6818\n",
      "Epoch 1993/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5531 - accuracy: 0.6818\n",
      "Epoch 1994/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5531 - accuracy: 0.6818\n",
      "Epoch 1995/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5530 - accuracy: 0.6818\n",
      "Epoch 1996/5000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5530 - accuracy: 0.6818\n",
      "Epoch 1997/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5529 - accuracy: 0.6818\n",
      "Epoch 1998/5000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5529 - accuracy: 0.6818\n",
      "Epoch 1999/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5528 - accuracy: 0.6818\n",
      "Epoch 2000/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5528 - accuracy: 0.6818\n",
      "Epoch 2001/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5528 - accuracy: 0.6818\n",
      "Epoch 2002/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5527 - accuracy: 0.6818\n",
      "Epoch 2003/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5527 - accuracy: 0.6818\n",
      "Epoch 2004/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5526 - accuracy: 0.6818\n",
      "Epoch 2005/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5526 - accuracy: 0.6818\n",
      "Epoch 2006/5000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.6818Epoch 4933/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4934/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4935/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4936/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4937/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4938/5000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4939/5000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4940/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4941/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4942/5000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4943/5000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4944/5000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4945/5000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4946/5000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4947/5000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4948/5000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4949/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4950/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4951/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4952/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4953/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4954/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4955/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4956/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4957/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4958/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4959/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4960/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4961/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4962/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4963/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4964/5000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4965/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4966/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4967/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4968/5000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4969/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4970/5000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4971/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4972/5000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4973/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4974/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4975/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4976/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4977/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4978/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4979/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4980/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4981/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4982/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4983/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4984/5000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4985/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4986/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4987/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4988/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4989/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4990/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4991/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4992/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4993/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4994/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4995/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4996/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4997/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4998/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4999/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 5000/5000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4631 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27963da9880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape=(2,), activation='sigmoid' , kernel_initializer= 'ones' , bias_initializer= 'zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_scaled,y_train, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61106ba0-3920-4c3d-b841-2836d53734f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.3550 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3549775183200836, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866176dd-a395-49cf-9c42-84dcac96d963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "2   0.47              1\n",
       "10  0.18              1\n",
       "21  0.26              0\n",
       "11  0.28              1\n",
       "14  0.49              1\n",
       "9   0.61              1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22a146c-eb1c-4a40-9ee0-d74865fe3039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.70548487],\n",
       "       [0.35569552],\n",
       "       [0.16827849],\n",
       "       [0.47801173],\n",
       "       [0.7260697 ],\n",
       "       [0.82949835]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb407c51-4151-4366-b48c-e07e0777f872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "10    0\n",
       "21    0\n",
       "11    0\n",
       "14    1\n",
       "9     1\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43154664-2b3f-4141-9cca-9de1eb5cdcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.060867 ],\n",
       "        [1.4086502]], dtype=float32),\n",
       " array([-2.9137027], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef,intercept = model.get_weights()\n",
    "coef,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3fe3751-521b-4470-8514-4876e67d6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now crosscheck of predicted model value by raw method\n",
    "\n",
    "def sigmoid(x):\n",
    "    import math\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b0d7be-e98a-4743-a06f-14a4111fca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age, affordibility):\n",
    "    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2246d74b-81e4-4472-a0b9-958840575fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true,y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,(1-epsilon)) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new) + (1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daf88810-9a0d-4d1f-8f17-68c74f7cd5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_numpy(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d94aaf7-8fdf-4d56-9b77-da443eabf27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\AppData\\Local\\Temp\\ipykernel_4228\\3236369613.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7054848693136117"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction model works properly\n",
    "\n",
    "prediction_function(.47, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f96d46c-42ce-432e-b6ec-52573d466fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age, affordibility, y_true, epochs, loss_thresold):\n",
    "    # w1, w2, bias\n",
    "    w1=w2=1\n",
    "    bias=0\n",
    "    learning_rate=0.5\n",
    "    n=len(age)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1*age + w2*affordibility + bias\n",
    "        y_predicted = sigmoid_numpy(weighted_sum)\n",
    "\n",
    "        loss = log_loss(y_true, y_predicted)\n",
    "    \n",
    "        w1d = (1/n)*np.dot(np.transpose(age), (y_predicted-y_true))\n",
    "        w2d = (1/n)*np.dot(np.transpose(affordibility),(y_predicted-y_true))\n",
    "    \n",
    "        bias_d = np.mean(y_predicted-y_true)\n",
    "    \n",
    "        w1= w1- learning_rate*w1d\n",
    "        w2 = w2 - learning_rate*w2d\n",
    "        bias = bias - learning_rate + bias_d\n",
    "    \n",
    "        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "\n",
    "        if loss<=loss_thresold:\n",
    "            break\n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b29692c-9290-4590-9bce-644af7a6403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.974907633470177, w2:0.948348125394529, bias:-0.27316264527262835, loss:0.7113403233723417\n",
      "Epoch:1, w1:0.9620300855866085, w2:0.915063748814626, bias:-0.6082254440416607, loss:0.6522828988560008\n",
      "Epoch:2, w1:0.9649149991849144, w2:0.9060870343188192, bias:-1.0224949874944445, loss:0.6085289626774781\n",
      "Epoch:3, w1:0.9874959162061404, w2:0.9283988150631846, bias:-1.5346870619948463, loss:0.5932298838909815\n",
      "Epoch:4, w1:1.0330500528533009, w2:0.9885107079147643, bias:-2.159581941311168, loss:0.6252554540616029\n",
      "Epoch:5, w1:1.1024200304274125, w2:1.0893858295415275, bias:-2.899483203368081, loss:0.7254084719207098\n",
      "Epoch:6, w1:1.192718331197512, w2:1.2275431325233526, bias:-3.7387376297900117, loss:0.9063731959059237\n",
      "Epoch:7, w1:1.2982774978565368, w2:1.3938881455911416, bias:-4.64924869924984, loss:1.1633292373978399\n",
      "Epoch:8, w1:1.4132517343338946, w2:1.5781531493330572, bias:-5.603077554407714, loss:1.4768477182282593\n",
      "Epoch:9, w1:1.5333776226074383, w2:1.7724591929689812, bias:-6.580314450089822, loss:1.8250955119828127\n",
      "Epoch:10, w1:1.656127468989443, w2:1.9719749359050591, bias:-7.569349382745555, loss:2.1920690738806305\n",
      "Epoch:11, w1:1.780164890827683, w2:2.174083758531919, bias:-8.56412161188758, loss:2.5684206947497468\n",
      "Epoch:12, w1:1.9048231855624624, w2:2.377456627472657, bias:-9.56163847520041, loss:2.9493002676886406\n",
      "Epoch:13, w1:2.029778691025329, w2:2.581439523824849, bias:-10.560459799811783, loss:3.3323314611904524\n",
      "Epoch:14, w1:2.1548761244885553, w2:2.785715443428025, bias:-11.559899957772782, loss:3.716379247113795\n",
      "Epoch:15, w1:2.2800413162157924, w2:2.990131820850904, bias:-12.559633749222717, loss:4.100906860777051\n",
      "Epoch:16, w1:2.4052388776470908, w2:3.194615467799266, bias:-13.559507010714928, loss:4.48566116988194\n",
      "Epoch:17, w1:2.530451917659031, w2:3.399131323567211, bias:-14.559446601696012, loss:4.870522761681851\n",
      "Epoch:18, w1:2.655672366655073, w2:3.6036626011685113, bias:-15.55941777775856, loss:5.255435217377868\n",
      "Epoch:19, w1:2.7808963653659835, w2:3.8082012639065335, bias:-16.55940401170044, loss:5.640371830064111\n",
      "Epoch:20, w1:2.9061220662028986, w2:4.012743463916164, bias:-17.559397431790167, loss:6.025319933601512\n",
      "Epoch:21, w1:3.0313485838238856, w2:4.217287358564085, bias:-18.55939428447991, loss:6.410273510485722\n",
      "Epoch:22, w1:3.1565754936356583, w2:4.421832065273268, bias:-19.55939277811595, loss:6.7952296975174695\n",
      "Epoch:23, w1:3.281802591866401, w2:4.626377161211144, bias:-20.559392056744958, loss:7.180187130547987\n",
      "Epoch:24, w1:3.4070297806614516, w2:4.830922443754626, bias:-21.559391711125016, loss:7.565145158897795\n",
      "Epoch:25, w1:3.532257013004474, w2:5.035467815782456, bias:-22.559391545461157, loss:7.950103471897473\n",
      "Epoch:26, w1:3.657484266295128, w2:5.240013230731344, bias:-23.55939146602341, loss:8.335061921091205\n",
      "Epoch:27, w1:3.7827115296652947, w2:5.444558666271965, bias:-24.559391427918523, loss:8.720020435486218\n",
      "Epoch:28, w1:3.907938797886854, w2:5.649104111693858, bias:-25.55939140963432, loss:9.10497898111149\n",
      "Epoch:29, w1:4.033166068444038, w2:5.853649561858479, bias:-26.559391400858207, loss:9.489937541702306\n",
      "Epoch:30, w1:4.158393340125926, w2:6.058195014299964, bias:-27.55939139664464, loss:9.874896109467537\n",
      "Epoch:31, w1:4.283620612349521, w2:6.262740467834747, bias:-28.559391394621098, loss:10.259854680673426\n",
      "Epoch:32, w1:4.408847884834076, w2:6.4672859218946135, bias:-29.559391393649065, loss:10.64481325352992\n",
      "Epoch:33, w1:4.5340751574443665, w2:6.6718313762067165, bias:-30.55939139318203, loss:11.029771827178509\n",
      "Epoch:34, w1:4.6593024301152495, w2:6.8763768306400115, bias:-31.55939139295758, loss:11.414730401207333\n",
      "Epoch:35, w1:4.784529702815337, w2:7.080922285131547, bias:-32.55939139284969, loss:11.799688975418718\n",
      "Epoch:36, w1:4.909756975529501, w2:7.285467739651076, bias:-33.55939139279782, loss:12.18464754971779\n",
      "Epoch:37, w1:5.034984248250453, w2:7.490013194184063, bias:-34.55939139277287, loss:12.569606124058977\n",
      "Epoch:38, w1:5.160211520974677, w2:7.69455864872352, bias:-35.55939139276088, loss:12.954564698420409\n",
      "Epoch:39, w1:5.28543879370048, w2:7.899104103266089, bias:-36.55939139275511, loss:13.339523272791569\n",
      "Epoch:40, w1:5.410666066427043, w2:8.103649557810156, bias:-37.55939139275233, loss:13.692697515375613\n",
      "Epoch:41, w1:5.535893339153974, w2:8.308195012354943, bias:-38.559391392750996, loss:14.033624581489356\n",
      "Epoch:42, w1:5.661120611881081, w2:8.512740466900077, bias:-39.55939139275035, loss:14.3427753296792\n",
      "Epoch:43, w1:5.786347884608274, w2:8.717285921445377, bias:-40.55939139275004, loss:14.64166313959613\n",
      "Epoch:44, w1:5.911575157335508, w2:8.921831375990758, bias:-41.55939139274989, loss:14.940550949513277\n",
      "Epoch:45, w1:6.036802430062762, w2:9.126376830536177, bias:-42.559391392749816, loss:15.239438759430527\n",
      "Epoch:46, w1:6.162029702790026, w2:9.330922285081614, bias:-43.55939139274978, loss:15.53832656934784\n",
      "Epoch:47, w1:6.287256975517294, w2:9.53546773962706, bias:-44.55939139274977, loss:15.83721437926517\n",
      "Epoch:48, w1:6.4124842482445645, w2:9.74001319417251, bias:-45.55939139274976, loss:16.136102189182512\n",
      "Epoch:49, w1:6.537711520971836, w2:9.944558648717964, bias:-46.55939139274975, loss:16.434989999099862\n",
      "Epoch:50, w1:6.662938793699109, w2:10.149104103263417, bias:-47.55939139274975, loss:16.733877809017216\n",
      "Epoch:51, w1:6.788166066426381, w2:10.35364955780887, bias:-48.55939139274975, loss:17.02338673815748\n",
      "Epoch:52, w1:6.913393339153654, w2:10.558195012354325, bias:-49.55939139274975, loss:17.223351749576974\n",
      "Epoch:53, w1:7.038620611880926, w2:10.76274046689978, bias:-50.55939139274975, loss:17.26938819745534\n",
      "Epoch:54, w1:7.163847884608199, w2:10.967285921445235, bias:-51.55939139274975, loss:17.26938819745534\n",
      "Epoch:55, w1:7.289075157335471, w2:11.17183137599069, bias:-52.55939139274975, loss:17.26938819745534\n",
      "Epoch:56, w1:7.414302430062744, w2:11.376376830536145, bias:-53.55939139274975, loss:17.26938819745534\n",
      "Epoch:57, w1:7.539529702790016, w2:11.5809222850816, bias:-54.55939139274975, loss:17.26938819745534\n",
      "Epoch:58, w1:7.664756975517289, w2:11.785467739627055, bias:-55.55939139274975, loss:17.26938819745534\n",
      "Epoch:59, w1:7.789984248244561, w2:11.99001319417251, bias:-56.55939139274975, loss:17.26938819745534\n",
      "Epoch:60, w1:7.915211520971834, w2:12.194558648717965, bias:-57.55939139274975, loss:17.26938819745534\n",
      "Epoch:61, w1:8.040438793699106, w2:12.39910410326342, bias:-58.55939139274975, loss:17.26938819745534\n",
      "Epoch:62, w1:8.165666066426379, w2:12.603649557808875, bias:-59.55939139274975, loss:17.26938819745534\n",
      "Epoch:63, w1:8.290893339153651, w2:12.80819501235433, bias:-60.55939139274975, loss:17.26938819745534\n",
      "Epoch:64, w1:8.416120611880924, w2:13.012740466899785, bias:-61.55939139274975, loss:17.26938819745534\n",
      "Epoch:65, w1:8.541347884608196, w2:13.21728592144524, bias:-62.55939139274975, loss:17.26938819745534\n",
      "Epoch:66, w1:8.666575157335469, w2:13.421831375990696, bias:-63.55939139274975, loss:17.26938819745534\n",
      "Epoch:67, w1:8.791802430062742, w2:13.62637683053615, bias:-64.55939139274975, loss:17.26938819745534\n",
      "Epoch:68, w1:8.917029702790014, w2:13.830922285081606, bias:-65.55939139274975, loss:17.26938819745534\n",
      "Epoch:69, w1:9.042256975517287, w2:14.03546773962706, bias:-66.55939139274975, loss:17.26938819745534\n",
      "Epoch:70, w1:9.167484248244559, w2:14.240013194172516, bias:-67.55939139274975, loss:17.26938819745534\n",
      "Epoch:71, w1:9.292711520971832, w2:14.44455864871797, bias:-68.55939139274975, loss:17.26938819745534\n",
      "Epoch:72, w1:9.417938793699104, w2:14.649104103263426, bias:-69.55939139274975, loss:17.26938819745534\n",
      "Epoch:73, w1:9.543166066426377, w2:14.85364955780888, bias:-70.55939139274975, loss:17.26938819745534\n",
      "Epoch:74, w1:9.66839333915365, w2:15.058195012354336, bias:-71.55939139274975, loss:17.26938819745534\n",
      "Epoch:75, w1:9.793620611880922, w2:15.26274046689979, bias:-72.55939139274975, loss:17.26938819745534\n",
      "Epoch:76, w1:9.918847884608194, w2:15.467285921445246, bias:-73.55939139274975, loss:17.26938819745534\n",
      "Epoch:77, w1:10.044075157335467, w2:15.6718313759907, bias:-74.55939139274975, loss:17.26938819745534\n",
      "Epoch:78, w1:10.16930243006274, w2:15.876376830536156, bias:-75.55939139274975, loss:17.26938819745534\n",
      "Epoch:79, w1:10.294529702790012, w2:16.08092228508161, bias:-76.55939139274975, loss:17.26938819745534\n",
      "Epoch:80, w1:10.419756975517284, w2:16.285467739627062, bias:-77.55939139274975, loss:17.26938819745534\n",
      "Epoch:81, w1:10.544984248244557, w2:16.490013194172516, bias:-78.55939139274975, loss:17.26938819745534\n",
      "Epoch:82, w1:10.67021152097183, w2:16.69455864871797, bias:-79.55939139274975, loss:17.26938819745534\n",
      "Epoch:83, w1:10.795438793699102, w2:16.899104103263422, bias:-80.55939139274975, loss:17.26938819745534\n",
      "Epoch:84, w1:10.920666066426374, w2:17.103649557808875, bias:-81.55939139274975, loss:17.26938819745534\n",
      "Epoch:85, w1:11.045893339153647, w2:17.30819501235433, bias:-82.55939139274975, loss:17.26938819745534\n",
      "Epoch:86, w1:11.17112061188092, w2:17.512740466899782, bias:-83.55939139274975, loss:17.26938819745534\n",
      "Epoch:87, w1:11.296347884608192, w2:17.717285921445235, bias:-84.55939139274975, loss:17.26938819745534\n",
      "Epoch:88, w1:11.421575157335464, w2:17.92183137599069, bias:-85.55939139274975, loss:17.26938819745534\n",
      "Epoch:89, w1:11.546802430062737, w2:18.12637683053614, bias:-86.55939139274975, loss:17.26938819745534\n",
      "Epoch:90, w1:11.67202970279001, w2:18.330922285081595, bias:-87.55939139274975, loss:17.26938819745534\n",
      "Epoch:91, w1:11.797256975517282, w2:18.535467739627048, bias:-88.55939139274975, loss:17.26938819745534\n",
      "Epoch:92, w1:11.922484248244555, w2:18.7400131941725, bias:-89.55939139274975, loss:17.26938819745534\n",
      "Epoch:93, w1:12.047711520971827, w2:18.944558648717955, bias:-90.55939139274975, loss:17.26938819745534\n",
      "Epoch:94, w1:12.1729387936991, w2:19.149104103263408, bias:-91.55939139274975, loss:17.26938819745534\n",
      "Epoch:95, w1:12.298166066426372, w2:19.35364955780886, bias:-92.55939139274975, loss:17.26938819745534\n",
      "Epoch:96, w1:12.423393339153645, w2:19.558195012354314, bias:-93.55939139274975, loss:17.26938819745534\n",
      "Epoch:97, w1:12.548620611880917, w2:19.762740466899768, bias:-94.55939139274975, loss:17.26938819745534\n",
      "Epoch:98, w1:12.67384788460819, w2:19.96728592144522, bias:-95.55939139274975, loss:17.26938819745534\n",
      "Epoch:99, w1:12.799075157335462, w2:20.171831375990674, bias:-96.55939139274975, loss:17.26938819745534\n",
      "Epoch:100, w1:12.924302430062735, w2:20.376376830536127, bias:-97.55939139274975, loss:17.26938819745534\n",
      "Epoch:101, w1:13.049529702790007, w2:20.58092228508158, bias:-98.55939139274975, loss:17.26938819745534\n",
      "Epoch:102, w1:13.17475697551728, w2:20.785467739627034, bias:-99.55939139274975, loss:17.26938819745534\n",
      "Epoch:103, w1:13.299984248244552, w2:20.990013194172487, bias:-100.55939139274975, loss:17.26938819745534\n",
      "Epoch:104, w1:13.425211520971825, w2:21.19455864871794, bias:-101.55939139274975, loss:17.26938819745534\n",
      "Epoch:105, w1:13.550438793699097, w2:21.399104103263394, bias:-102.55939139274975, loss:17.26938819745534\n",
      "Epoch:106, w1:13.67566606642637, w2:21.603649557808847, bias:-103.55939139274975, loss:17.26938819745534\n",
      "Epoch:107, w1:13.800893339153642, w2:21.8081950123543, bias:-104.55939139274975, loss:17.26938819745534\n",
      "Epoch:108, w1:13.926120611880915, w2:22.012740466899753, bias:-105.55939139274975, loss:17.26938819745534\n",
      "Epoch:109, w1:14.051347884608187, w2:22.217285921445207, bias:-106.55939139274975, loss:17.26938819745534\n",
      "Epoch:110, w1:14.17657515733546, w2:22.42183137599066, bias:-107.55939139274975, loss:17.26938819745534\n",
      "Epoch:111, w1:14.301802430062732, w2:22.626376830536113, bias:-108.55939139274975, loss:17.26938819745534\n",
      "Epoch:112, w1:14.427029702790005, w2:22.830922285081567, bias:-109.55939139274975, loss:17.26938819745534\n",
      "Epoch:113, w1:14.552256975517277, w2:23.03546773962702, bias:-110.55939139274975, loss:17.26938819745534\n",
      "Epoch:114, w1:14.67748424824455, w2:23.240013194172473, bias:-111.55939139274975, loss:17.26938819745534\n",
      "Epoch:115, w1:14.802711520971823, w2:23.444558648717926, bias:-112.55939139274975, loss:17.26938819745534\n",
      "Epoch:116, w1:14.927938793699095, w2:23.64910410326338, bias:-113.55939139274975, loss:17.26938819745534\n",
      "Epoch:117, w1:15.053166066426368, w2:23.853649557808833, bias:-114.55939139274975, loss:17.26938819745534\n",
      "Epoch:118, w1:15.17839333915364, w2:24.058195012354286, bias:-115.55939139274975, loss:17.26938819745534\n",
      "Epoch:119, w1:15.303620611880913, w2:24.26274046689974, bias:-116.55939139274975, loss:17.26938819745534\n",
      "Epoch:120, w1:15.428847884608185, w2:24.467285921445193, bias:-117.55939139274975, loss:17.26938819745534\n",
      "Epoch:121, w1:15.554075157335458, w2:24.671831375990646, bias:-118.55939139274975, loss:17.26938819745534\n",
      "Epoch:122, w1:15.67930243006273, w2:24.8763768305361, bias:-119.55939139274975, loss:17.26938819745534\n",
      "Epoch:123, w1:15.804529702790003, w2:25.080922285081552, bias:-120.55939139274975, loss:17.26938819745534\n",
      "Epoch:124, w1:15.929756975517275, w2:25.285467739627006, bias:-121.55939139274975, loss:17.26938819745534\n",
      "Epoch:125, w1:16.054984248244548, w2:25.49001319417246, bias:-122.55939139274975, loss:17.26938819745534\n",
      "Epoch:126, w1:16.18021152097182, w2:25.694558648717912, bias:-123.55939139274975, loss:17.26938819745534\n",
      "Epoch:127, w1:16.305438793699093, w2:25.899104103263365, bias:-124.55939139274975, loss:17.26938819745534\n",
      "Epoch:128, w1:16.430666066426365, w2:26.10364955780882, bias:-125.55939139274975, loss:17.26938819745534\n",
      "Epoch:129, w1:16.555893339153638, w2:26.308195012354272, bias:-126.55939139274975, loss:17.26938819745534\n",
      "Epoch:130, w1:16.68112061188091, w2:26.512740466899725, bias:-127.55939139274975, loss:17.26938819745534\n",
      "Epoch:131, w1:16.806347884608183, w2:26.71728592144518, bias:-128.55939139274975, loss:17.26938819745534\n",
      "Epoch:132, w1:16.931575157335455, w2:26.92183137599063, bias:-129.55939139274975, loss:17.26938819745534\n",
      "Epoch:133, w1:17.056802430062728, w2:27.126376830536085, bias:-130.55939139274975, loss:17.26938819745534\n",
      "Epoch:134, w1:17.18202970279, w2:27.330922285081538, bias:-131.55939139274975, loss:17.26938819745534\n",
      "Epoch:135, w1:17.307256975517273, w2:27.53546773962699, bias:-132.55939139274975, loss:17.26938819745534\n",
      "Epoch:136, w1:17.432484248244545, w2:27.740013194172445, bias:-133.55939139274975, loss:17.26938819745534\n",
      "Epoch:137, w1:17.557711520971818, w2:27.944558648717898, bias:-134.55939139274975, loss:17.26938819745534\n",
      "Epoch:138, w1:17.68293879369909, w2:28.14910410326335, bias:-135.55939139274975, loss:17.26938819745534\n",
      "Epoch:139, w1:17.808166066426363, w2:28.353649557808804, bias:-136.55939139274975, loss:17.26938819745534\n",
      "Epoch:140, w1:17.933393339153636, w2:28.558195012354258, bias:-137.55939139274975, loss:17.26938819745534\n",
      "Epoch:141, w1:18.058620611880908, w2:28.76274046689971, bias:-138.55939139274975, loss:17.26938819745534\n",
      "Epoch:142, w1:18.18384788460818, w2:28.967285921445164, bias:-139.55939139274975, loss:17.26938819745534\n",
      "Epoch:143, w1:18.309075157335453, w2:29.171831375990617, bias:-140.55939139274975, loss:17.26938819745534\n",
      "Epoch:144, w1:18.434302430062726, w2:29.37637683053607, bias:-141.55939139274975, loss:17.26938819745534\n",
      "Epoch:145, w1:18.559529702789998, w2:29.580922285081524, bias:-142.55939139274975, loss:17.26938819745534\n",
      "Epoch:146, w1:18.68475697551727, w2:29.785467739626977, bias:-143.55939139274975, loss:17.26938819745534\n",
      "Epoch:147, w1:18.809984248244543, w2:29.99001319417243, bias:-144.55939139274975, loss:17.26938819745534\n",
      "Epoch:148, w1:18.935211520971816, w2:30.194558648717884, bias:-145.55939139274975, loss:17.26938819745534\n",
      "Epoch:149, w1:19.060438793699088, w2:30.399104103263337, bias:-146.55939139274975, loss:17.26938819745534\n",
      "Epoch:150, w1:19.18566606642636, w2:30.60364955780879, bias:-147.55939139274975, loss:17.26938819745534\n",
      "Epoch:151, w1:19.310893339153633, w2:30.808195012354243, bias:-148.55939139274975, loss:17.26938819745534\n",
      "Epoch:152, w1:19.436120611880906, w2:31.012740466899697, bias:-149.55939139274975, loss:17.26938819745534\n",
      "Epoch:153, w1:19.56134788460818, w2:31.21728592144515, bias:-150.55939139274975, loss:17.26938819745534\n",
      "Epoch:154, w1:19.68657515733545, w2:31.421831375990603, bias:-151.55939139274975, loss:17.26938819745534\n",
      "Epoch:155, w1:19.811802430062723, w2:31.626376830536056, bias:-152.55939139274975, loss:17.26938819745534\n",
      "Epoch:156, w1:19.937029702789996, w2:31.83092228508151, bias:-153.55939139274975, loss:17.26938819745534\n",
      "Epoch:157, w1:20.06225697551727, w2:32.03546773962697, bias:-154.55939139274975, loss:17.26938819745534\n",
      "Epoch:158, w1:20.18748424824454, w2:32.24001319417242, bias:-155.55939139274975, loss:17.26938819745534\n",
      "Epoch:159, w1:20.312711520971813, w2:32.44455864871787, bias:-156.55939139274975, loss:17.26938819745534\n",
      "Epoch:160, w1:20.437938793699086, w2:32.649104103263326, bias:-157.55939139274975, loss:17.26938819745534\n",
      "Epoch:161, w1:20.56316606642636, w2:32.85364955780878, bias:-158.55939139274975, loss:17.26938819745534\n",
      "Epoch:162, w1:20.68839333915363, w2:33.05819501235423, bias:-159.55939139274975, loss:17.26938819745534\n",
      "Epoch:163, w1:20.813620611880904, w2:33.262740466899686, bias:-160.55939139274975, loss:17.26938819745534\n",
      "Epoch:164, w1:20.938847884608176, w2:33.46728592144514, bias:-161.55939139274975, loss:17.26938819745534\n",
      "Epoch:165, w1:21.06407515733545, w2:33.67183137599059, bias:-162.55939139274975, loss:17.26938819745534\n",
      "Epoch:166, w1:21.18930243006272, w2:33.876376830536046, bias:-163.55939139274975, loss:17.26938819745534\n",
      "Epoch:167, w1:21.314529702789994, w2:34.0809222850815, bias:-164.55939139274975, loss:17.26938819745534\n",
      "Epoch:168, w1:21.439756975517266, w2:34.28546773962695, bias:-165.55939139274975, loss:17.26938819745534\n",
      "Epoch:169, w1:21.56498424824454, w2:34.490013194172406, bias:-166.55939139274975, loss:17.26938819745534\n",
      "Epoch:170, w1:21.69021152097181, w2:34.69455864871786, bias:-167.55939139274975, loss:17.26938819745534\n",
      "Epoch:171, w1:21.815438793699084, w2:34.89910410326331, bias:-168.55939139274975, loss:17.26938819745534\n",
      "Epoch:172, w1:21.940666066426356, w2:35.103649557808765, bias:-169.55939139274975, loss:17.26938819745534\n",
      "Epoch:173, w1:22.06589333915363, w2:35.30819501235422, bias:-170.55939139274975, loss:17.26938819745534\n",
      "Epoch:174, w1:22.1911206118809, w2:35.51274046689967, bias:-171.55939139274975, loss:17.26938819745534\n",
      "Epoch:175, w1:22.316347884608174, w2:35.717285921445125, bias:-172.55939139274975, loss:17.26938819745534\n",
      "Epoch:176, w1:22.441575157335446, w2:35.92183137599058, bias:-173.55939139274975, loss:17.26938819745534\n",
      "Epoch:177, w1:22.56680243006272, w2:36.12637683053603, bias:-174.55939139274975, loss:17.26938819745534\n",
      "Epoch:178, w1:22.69202970278999, w2:36.330922285081485, bias:-175.55939139274975, loss:17.26938819745534\n",
      "Epoch:179, w1:22.817256975517264, w2:36.53546773962694, bias:-176.55939139274975, loss:17.26938819745534\n",
      "Epoch:180, w1:22.942484248244536, w2:36.74001319417239, bias:-177.55939139274975, loss:17.26938819745534\n",
      "Epoch:181, w1:23.06771152097181, w2:36.944558648717845, bias:-178.55939139274975, loss:17.26938819745534\n",
      "Epoch:182, w1:23.19293879369908, w2:37.1491041032633, bias:-179.55939139274975, loss:17.26938819745534\n",
      "Epoch:183, w1:23.318166066426354, w2:37.35364955780875, bias:-180.55939139274975, loss:17.26938819745534\n",
      "Epoch:184, w1:23.443393339153626, w2:37.558195012354204, bias:-181.55939139274975, loss:17.26938819745534\n",
      "Epoch:185, w1:23.5686206118809, w2:37.76274046689966, bias:-182.55939139274975, loss:17.26938819745534\n",
      "Epoch:186, w1:23.69384788460817, w2:37.96728592144511, bias:-183.55939139274975, loss:17.26938819745534\n",
      "Epoch:187, w1:23.819075157335444, w2:38.171831375990564, bias:-184.55939139274975, loss:17.26938819745534\n",
      "Epoch:188, w1:23.944302430062717, w2:38.37637683053602, bias:-185.55939139274975, loss:17.26938819745534\n",
      "Epoch:189, w1:24.06952970278999, w2:38.58092228508147, bias:-186.55939139274975, loss:17.26938819745534\n",
      "Epoch:190, w1:24.19475697551726, w2:38.785467739626924, bias:-187.55939139274975, loss:17.26938819745534\n",
      "Epoch:191, w1:24.319984248244534, w2:38.99001319417238, bias:-188.55939139274975, loss:17.26938819745534\n",
      "Epoch:192, w1:24.445211520971807, w2:39.19455864871783, bias:-189.55939139274975, loss:17.26938819745534\n",
      "Epoch:193, w1:24.57043879369908, w2:39.399104103263284, bias:-190.55939139274975, loss:17.26938819745534\n",
      "Epoch:194, w1:24.69566606642635, w2:39.60364955780874, bias:-191.55939139274975, loss:17.26938819745534\n",
      "Epoch:195, w1:24.820893339153624, w2:39.80819501235419, bias:-192.55939139274975, loss:17.26938819745534\n",
      "Epoch:196, w1:24.946120611880897, w2:40.01274046689964, bias:-193.55939139274975, loss:17.26938819745534\n",
      "Epoch:197, w1:25.07134788460817, w2:40.2172859214451, bias:-194.55939139274975, loss:17.26938819745534\n",
      "Epoch:198, w1:25.19657515733544, w2:40.42183137599055, bias:-195.55939139274975, loss:17.26938819745534\n",
      "Epoch:199, w1:25.321802430062714, w2:40.626376830536, bias:-196.55939139274975, loss:17.26938819745534\n",
      "Epoch:200, w1:25.447029702789987, w2:40.830922285081456, bias:-197.55939139274975, loss:17.26938819745534\n",
      "Epoch:201, w1:25.57225697551726, w2:41.03546773962691, bias:-198.55939139274975, loss:17.26938819745534\n",
      "Epoch:202, w1:25.697484248244532, w2:41.24001319417236, bias:-199.55939139274975, loss:17.26938819745534\n",
      "Epoch:203, w1:25.822711520971804, w2:41.444558648717816, bias:-200.55939139274975, loss:17.26938819745534\n",
      "Epoch:204, w1:25.947938793699077, w2:41.64910410326327, bias:-201.55939139274975, loss:17.26938819745534\n",
      "Epoch:205, w1:26.07316606642635, w2:41.85364955780872, bias:-202.55939139274975, loss:17.26938819745534\n",
      "Epoch:206, w1:26.198393339153622, w2:42.058195012354176, bias:-203.55939139274975, loss:17.26938819745534\n",
      "Epoch:207, w1:26.323620611880894, w2:42.26274046689963, bias:-204.55939139274975, loss:17.26938819745534\n",
      "Epoch:208, w1:26.448847884608167, w2:42.46728592144508, bias:-205.55939139274975, loss:17.26938819745534\n",
      "Epoch:209, w1:26.57407515733544, w2:42.671831375990536, bias:-206.55939139274975, loss:17.26938819745534\n",
      "Epoch:210, w1:26.699302430062712, w2:42.87637683053599, bias:-207.55939139274975, loss:17.26938819745534\n",
      "Epoch:211, w1:26.824529702789984, w2:43.08092228508144, bias:-208.55939139274975, loss:17.26938819745534\n",
      "Epoch:212, w1:26.949756975517257, w2:43.285467739626895, bias:-209.55939139274975, loss:17.26938819745534\n",
      "Epoch:213, w1:27.07498424824453, w2:43.49001319417235, bias:-210.55939139274975, loss:17.26938819745534\n",
      "Epoch:214, w1:27.200211520971802, w2:43.6945586487178, bias:-211.55939139274975, loss:17.26938819745534\n",
      "Epoch:215, w1:27.325438793699075, w2:43.899104103263255, bias:-212.55939139274975, loss:17.26938819745534\n",
      "Epoch:216, w1:27.450666066426347, w2:44.10364955780871, bias:-213.55939139274975, loss:17.26938819745534\n",
      "Epoch:217, w1:27.57589333915362, w2:44.30819501235416, bias:-214.55939139274975, loss:17.26938819745534\n",
      "Epoch:218, w1:27.701120611880892, w2:44.512740466899615, bias:-215.55939139274975, loss:17.26938819745534\n",
      "Epoch:219, w1:27.826347884608165, w2:44.71728592144507, bias:-216.55939139274975, loss:17.26938819745534\n",
      "Epoch:220, w1:27.951575157335437, w2:44.92183137599052, bias:-217.55939139274975, loss:17.26938819745534\n",
      "Epoch:221, w1:28.07680243006271, w2:45.126376830535975, bias:-218.55939139274975, loss:17.26938819745534\n",
      "Epoch:222, w1:28.202029702789982, w2:45.33092228508143, bias:-219.55939139274975, loss:17.26938819745534\n",
      "Epoch:223, w1:28.327256975517255, w2:45.53546773962688, bias:-220.55939139274975, loss:17.26938819745534\n",
      "Epoch:224, w1:28.452484248244527, w2:45.740013194172334, bias:-221.55939139274975, loss:17.26938819745534\n",
      "Epoch:225, w1:28.5777115209718, w2:45.94455864871779, bias:-222.55939139274975, loss:17.26938819745534\n",
      "Epoch:226, w1:28.702938793699072, w2:46.14910410326324, bias:-223.55939139274975, loss:17.26938819745534\n",
      "Epoch:227, w1:28.828166066426345, w2:46.353649557808694, bias:-224.55939139274975, loss:17.26938819745534\n",
      "Epoch:228, w1:28.953393339153617, w2:46.55819501235415, bias:-225.55939139274975, loss:17.26938819745534\n",
      "Epoch:229, w1:29.07862061188089, w2:46.7627404668996, bias:-226.55939139274975, loss:17.26938819745534\n",
      "Epoch:230, w1:29.203847884608162, w2:46.967285921445054, bias:-227.55939139274975, loss:17.26938819745534\n",
      "Epoch:231, w1:29.329075157335435, w2:47.17183137599051, bias:-228.55939139274975, loss:17.26938819745534\n",
      "Epoch:232, w1:29.454302430062707, w2:47.37637683053596, bias:-229.55939139274975, loss:17.26938819745534\n",
      "Epoch:233, w1:29.57952970278998, w2:47.580922285081414, bias:-230.55939139274975, loss:17.26938819745534\n",
      "Epoch:234, w1:29.704756975517252, w2:47.78546773962687, bias:-231.55939139274975, loss:17.26938819745534\n",
      "Epoch:235, w1:29.829984248244525, w2:47.99001319417232, bias:-232.55939139274975, loss:17.26938819745534\n",
      "Epoch:236, w1:29.955211520971798, w2:48.19455864871777, bias:-233.55939139274975, loss:17.26938819745534\n",
      "Epoch:237, w1:30.08043879369907, w2:48.39910410326323, bias:-234.55939139274975, loss:17.26938819745534\n",
      "Epoch:238, w1:30.205666066426343, w2:48.60364955780868, bias:-235.55939139274975, loss:17.26938819745534\n",
      "Epoch:239, w1:30.330893339153615, w2:48.80819501235413, bias:-236.55939139274975, loss:17.26938819745534\n",
      "Epoch:240, w1:30.456120611880888, w2:49.01274046689959, bias:-237.55939139274975, loss:17.26938819745534\n",
      "Epoch:241, w1:30.58134788460816, w2:49.21728592144504, bias:-238.55939139274975, loss:17.26938819745534\n",
      "Epoch:242, w1:30.706575157335433, w2:49.42183137599049, bias:-239.55939139274975, loss:17.26938819745534\n",
      "Epoch:243, w1:30.831802430062705, w2:49.626376830535946, bias:-240.55939139274975, loss:17.26938819745534\n",
      "Epoch:244, w1:30.957029702789978, w2:49.8309222850814, bias:-241.55939139274975, loss:17.26938819745534\n",
      "Epoch:245, w1:31.08225697551725, w2:50.03546773962685, bias:-242.55939139274975, loss:17.26938819745534\n",
      "Epoch:246, w1:31.207484248244523, w2:50.240013194172306, bias:-243.55939139274975, loss:17.26938819745534\n",
      "Epoch:247, w1:31.332711520971795, w2:50.44455864871776, bias:-244.55939139274975, loss:17.26938819745534\n",
      "Epoch:248, w1:31.457938793699068, w2:50.64910410326321, bias:-245.55939139274975, loss:17.26938819745534\n",
      "Epoch:249, w1:31.58316606642634, w2:50.853649557808666, bias:-246.55939139274975, loss:17.26938819745534\n",
      "Epoch:250, w1:31.708393339153613, w2:51.05819501235412, bias:-247.55939139274975, loss:17.26938819745534\n",
      "Epoch:251, w1:31.833620611880885, w2:51.26274046689957, bias:-248.55939139274975, loss:17.26938819745534\n",
      "Epoch:252, w1:31.958847884608158, w2:51.467285921445026, bias:-249.55939139274975, loss:17.26938819745534\n",
      "Epoch:253, w1:32.084075157335434, w2:51.67183137599048, bias:-250.55939139274975, loss:17.26938819745534\n",
      "Epoch:254, w1:32.209302430062706, w2:51.87637683053593, bias:-251.55939139274975, loss:17.26938819745534\n",
      "Epoch:255, w1:32.33452970278998, w2:52.080922285081385, bias:-252.55939139274975, loss:17.26938819745534\n",
      "Epoch:256, w1:32.45975697551725, w2:52.28546773962684, bias:-253.55939139274975, loss:17.26938819745534\n",
      "Epoch:257, w1:32.584984248244524, w2:52.49001319417229, bias:-254.55939139274975, loss:17.26938819745534\n",
      "Epoch:258, w1:32.7102115209718, w2:52.694558648717745, bias:-255.55939139274975, loss:17.26938819745534\n",
      "Epoch:259, w1:32.83543879369907, w2:52.8991041032632, bias:-256.5593913927497, loss:17.26938819745534\n",
      "Epoch:260, w1:32.96066606642634, w2:53.10364955780865, bias:-257.5593913927497, loss:17.26938819745534\n",
      "Epoch:261, w1:33.085893339153614, w2:53.308195012354105, bias:-258.5593913927497, loss:17.26938819745534\n",
      "Epoch:262, w1:33.21112061188089, w2:53.51274046689956, bias:-259.5593913927497, loss:17.26938819745534\n",
      "Epoch:263, w1:33.33634788460816, w2:53.71728592144501, bias:-260.5593913927497, loss:17.26938819745534\n",
      "Epoch:264, w1:33.46157515733543, w2:53.921831375990465, bias:-261.5593913927497, loss:17.26938819745534\n",
      "Epoch:265, w1:33.586802430062704, w2:54.12637683053592, bias:-262.5593913927497, loss:17.26938819745534\n",
      "Epoch:266, w1:33.71202970278998, w2:54.33092228508137, bias:-263.5593913927497, loss:17.26938819745534\n",
      "Epoch:267, w1:33.83725697551725, w2:54.535467739626824, bias:-264.5593913927497, loss:17.26938819745534\n",
      "Epoch:268, w1:33.96248424824452, w2:54.74001319417228, bias:-265.5593913927497, loss:17.26938819745534\n",
      "Epoch:269, w1:34.087711520971794, w2:54.94455864871773, bias:-266.5593913927497, loss:17.26938819745534\n",
      "Epoch:270, w1:34.21293879369907, w2:55.149104103263184, bias:-267.5593913927497, loss:17.26938819745534\n",
      "Epoch:271, w1:34.33816606642634, w2:55.35364955780864, bias:-268.5593913927497, loss:17.26938819745534\n",
      "Epoch:272, w1:34.46339333915361, w2:55.55819501235409, bias:-269.5593913927497, loss:17.26938819745534\n",
      "Epoch:273, w1:34.588620611880884, w2:55.762740466899544, bias:-270.5593913927497, loss:17.26938819745534\n",
      "Epoch:274, w1:34.71384788460816, w2:55.967285921445, bias:-271.5593913927497, loss:17.26938819745534\n",
      "Epoch:275, w1:34.83907515733543, w2:56.17183137599045, bias:-272.5593913927497, loss:17.26938819745534\n",
      "Epoch:276, w1:34.9643024300627, w2:56.376376830535904, bias:-273.5593913927497, loss:17.26938819745534\n",
      "Epoch:277, w1:35.089529702789974, w2:56.58092228508136, bias:-274.5593913927497, loss:17.26938819745534\n",
      "Epoch:278, w1:35.21475697551725, w2:56.78546773962681, bias:-275.5593913927497, loss:17.26938819745534\n",
      "Epoch:279, w1:35.33998424824452, w2:56.99001319417226, bias:-276.5593913927497, loss:17.26938819745534\n",
      "Epoch:280, w1:35.46521152097179, w2:57.19455864871772, bias:-277.5593913927497, loss:17.26938819745534\n",
      "Epoch:281, w1:35.590438793699064, w2:57.39910410326317, bias:-278.5593913927497, loss:17.26938819745534\n",
      "Epoch:282, w1:35.71566606642634, w2:57.60364955780862, bias:-279.5593913927497, loss:17.26938819745534\n",
      "Epoch:283, w1:35.84089333915361, w2:57.808195012354076, bias:-280.5593913927497, loss:17.26938819745534\n",
      "Epoch:284, w1:35.96612061188088, w2:58.01274046689953, bias:-281.5593913927497, loss:17.26938819745534\n",
      "Epoch:285, w1:36.091347884608155, w2:58.21728592144498, bias:-282.5593913927497, loss:17.26938819745534\n",
      "Epoch:286, w1:36.21657515733543, w2:58.421831375990436, bias:-283.5593913927497, loss:17.26938819745534\n",
      "Epoch:287, w1:36.3418024300627, w2:58.62637683053589, bias:-284.5593913927497, loss:17.26938819745534\n",
      "Epoch:288, w1:36.46702970278997, w2:58.83092228508134, bias:-285.5593913927497, loss:17.26938819745534\n",
      "Epoch:289, w1:36.592256975517245, w2:59.035467739626796, bias:-286.5593913927497, loss:17.26938819745534\n",
      "Epoch:290, w1:36.71748424824452, w2:59.24001319417225, bias:-287.5593913927497, loss:17.26938819745534\n",
      "Epoch:291, w1:36.84271152097179, w2:59.4445586487177, bias:-288.5593913927497, loss:17.26938819745534\n",
      "Epoch:292, w1:36.96793879369906, w2:59.649104103263156, bias:-289.5593913927497, loss:17.26938819745534\n",
      "Epoch:293, w1:37.093166066426335, w2:59.85364955780861, bias:-290.5593913927497, loss:17.26938819745534\n",
      "Epoch:294, w1:37.21839333915361, w2:60.05819501235406, bias:-291.5593913927497, loss:17.26938819745534\n",
      "Epoch:295, w1:37.34362061188088, w2:60.262740466899515, bias:-292.5593913927497, loss:17.26938819745534\n",
      "Epoch:296, w1:37.46884788460815, w2:60.46728592144497, bias:-293.5593913927497, loss:17.26938819745534\n",
      "Epoch:297, w1:37.594075157335425, w2:60.67183137599042, bias:-294.5593913927497, loss:17.26938819745534\n",
      "Epoch:298, w1:37.7193024300627, w2:60.876376830535875, bias:-295.5593913927497, loss:17.26938819745534\n",
      "Epoch:299, w1:37.84452970278997, w2:61.08092228508133, bias:-296.5593913927497, loss:17.26938819745534\n",
      "Epoch:300, w1:37.96975697551724, w2:61.28546773962678, bias:-297.5593913927497, loss:17.26938819745534\n",
      "Epoch:301, w1:38.094984248244515, w2:61.490013194172235, bias:-298.5593913927497, loss:17.26938819745534\n",
      "Epoch:302, w1:38.22021152097179, w2:61.69455864871769, bias:-299.5593913927497, loss:17.26938819745534\n",
      "Epoch:303, w1:38.34543879369906, w2:61.89910410326314, bias:-300.5593913927497, loss:17.26938819745534\n",
      "Epoch:304, w1:38.47066606642633, w2:62.103649557808595, bias:-301.5593913927497, loss:17.26938819745534\n",
      "Epoch:305, w1:38.595893339153605, w2:62.30819501235405, bias:-302.5593913927497, loss:17.26938819745534\n",
      "Epoch:306, w1:38.72112061188088, w2:62.5127404668995, bias:-303.5593913927497, loss:17.26938819745534\n",
      "Epoch:307, w1:38.84634788460815, w2:62.717285921444955, bias:-304.5593913927497, loss:17.26938819745534\n",
      "Epoch:308, w1:38.97157515733542, w2:62.92183137599041, bias:-305.5593913927497, loss:17.26938819745534\n",
      "Epoch:309, w1:39.096802430062695, w2:63.12637683053586, bias:-306.5593913927497, loss:17.26938819745534\n",
      "Epoch:310, w1:39.22202970278997, w2:63.330922285081314, bias:-307.5593913927497, loss:17.26938819745534\n",
      "Epoch:311, w1:39.34725697551724, w2:63.53546773962677, bias:-308.5593913927497, loss:17.26938819745534\n",
      "Epoch:312, w1:39.47248424824451, w2:63.74001319417222, bias:-309.5593913927497, loss:17.26938819745534\n",
      "Epoch:313, w1:39.597711520971785, w2:63.944558648717674, bias:-310.5593913927497, loss:17.26938819745534\n",
      "Epoch:314, w1:39.72293879369906, w2:64.14910410326313, bias:-311.5593913927497, loss:17.26938819745534\n",
      "Epoch:315, w1:39.84816606642633, w2:64.35364955780858, bias:-312.5593913927497, loss:17.26938819745534\n",
      "Epoch:316, w1:39.9733933391536, w2:64.55819501235403, bias:-313.5593913927497, loss:17.26938819745534\n",
      "Epoch:317, w1:40.098620611880875, w2:64.76274046689949, bias:-314.5593913927497, loss:17.26938819745534\n",
      "Epoch:318, w1:40.22384788460815, w2:64.96728592144494, bias:-315.5593913927497, loss:17.26938819745534\n",
      "Epoch:319, w1:40.34907515733542, w2:65.1718313759904, bias:-316.5593913927497, loss:17.26938819745534\n",
      "Epoch:320, w1:40.47430243006269, w2:65.37637683053585, bias:-317.5593913927497, loss:17.26938819745534\n",
      "Epoch:321, w1:40.599529702789965, w2:65.5809222850813, bias:-318.5593913927497, loss:17.26938819745534\n",
      "Epoch:322, w1:40.72475697551724, w2:65.78546773962675, bias:-319.5593913927497, loss:17.26938819745534\n",
      "Epoch:323, w1:40.84998424824451, w2:65.9900131941722, bias:-320.5593913927497, loss:17.26938819745534\n",
      "Epoch:324, w1:40.97521152097178, w2:66.19455864871766, bias:-321.5593913927497, loss:17.26938819745534\n",
      "Epoch:325, w1:41.100438793699055, w2:66.39910410326311, bias:-322.5593913927497, loss:17.26938819745534\n",
      "Epoch:326, w1:41.22566606642633, w2:66.60364955780857, bias:-323.5593913927497, loss:17.26938819745534\n",
      "Epoch:327, w1:41.3508933391536, w2:66.80819501235402, bias:-324.5593913927497, loss:17.26938819745534\n",
      "Epoch:328, w1:41.47612061188087, w2:67.01274046689947, bias:-325.5593913927497, loss:17.26938819745534\n",
      "Epoch:329, w1:41.601347884608145, w2:67.21728592144493, bias:-326.5593913927497, loss:17.26938819745534\n",
      "Epoch:330, w1:41.72657515733542, w2:67.42183137599038, bias:-327.5593913927497, loss:17.26938819745534\n",
      "Epoch:331, w1:41.85180243006269, w2:67.62637683053583, bias:-328.5593913927497, loss:17.26938819745534\n",
      "Epoch:332, w1:41.97702970278996, w2:67.83092228508129, bias:-329.5593913927497, loss:17.26938819745534\n",
      "Epoch:333, w1:42.102256975517236, w2:68.03546773962674, bias:-330.5593913927497, loss:17.26938819745534\n",
      "Epoch:334, w1:42.22748424824451, w2:68.24001319417219, bias:-331.5593913927497, loss:17.26938819745534\n",
      "Epoch:335, w1:42.35271152097178, w2:68.44455864871765, bias:-332.5593913927497, loss:17.26938819745534\n",
      "Epoch:336, w1:42.47793879369905, w2:68.6491041032631, bias:-333.5593913927497, loss:17.26938819745534\n",
      "Epoch:337, w1:42.603166066426326, w2:68.85364955780855, bias:-334.5593913927497, loss:17.26938819745534\n",
      "Epoch:338, w1:42.7283933391536, w2:69.058195012354, bias:-335.5593913927497, loss:17.26938819745534\n",
      "Epoch:339, w1:42.85362061188087, w2:69.26274046689946, bias:-336.5593913927497, loss:17.26938819745534\n",
      "Epoch:340, w1:42.97884788460814, w2:69.46728592144491, bias:-337.5593913927497, loss:17.26938819745534\n",
      "Epoch:341, w1:43.104075157335416, w2:69.67183137599037, bias:-338.5593913927497, loss:17.26938819745534\n",
      "Epoch:342, w1:43.22930243006269, w2:69.87637683053582, bias:-339.5593913927497, loss:17.26938819745534\n",
      "Epoch:343, w1:43.35452970278996, w2:70.08092228508127, bias:-340.5593913927497, loss:17.26938819745534\n",
      "Epoch:344, w1:43.47975697551723, w2:70.28546773962672, bias:-341.5593913927497, loss:17.26938819745534\n",
      "Epoch:345, w1:43.604984248244506, w2:70.49001319417218, bias:-342.5593913927497, loss:17.26938819745534\n",
      "Epoch:346, w1:43.73021152097178, w2:70.69455864871763, bias:-343.5593913927497, loss:17.26938819745534\n",
      "Epoch:347, w1:43.85543879369905, w2:70.89910410326308, bias:-344.5593913927497, loss:17.26938819745534\n",
      "Epoch:348, w1:43.98066606642632, w2:71.10364955780854, bias:-345.5593913927497, loss:17.26938819745534\n",
      "Epoch:349, w1:44.105893339153596, w2:71.30819501235399, bias:-346.5593913927497, loss:17.26938819745534\n",
      "Epoch:350, w1:44.23112061188087, w2:71.51274046689944, bias:-347.5593913927497, loss:17.26938819745534\n",
      "Epoch:351, w1:44.35634788460814, w2:71.7172859214449, bias:-348.5593913927497, loss:17.26938819745534\n",
      "Epoch:352, w1:44.48157515733541, w2:71.92183137599035, bias:-349.5593913927497, loss:17.26938819745534\n",
      "Epoch:353, w1:44.606802430062686, w2:72.1263768305358, bias:-350.5593913927497, loss:17.26938819745534\n",
      "Epoch:354, w1:44.73202970278996, w2:72.33092228508126, bias:-351.5593913927497, loss:17.26938819745534\n",
      "Epoch:355, w1:44.85725697551723, w2:72.53546773962671, bias:-352.5593913927497, loss:17.26938819745534\n",
      "Epoch:356, w1:44.9824842482445, w2:72.74001319417216, bias:-353.5593913927497, loss:17.26938819745534\n",
      "Epoch:357, w1:45.107711520971776, w2:72.94455864871762, bias:-354.5593913927497, loss:17.26938819745534\n",
      "Epoch:358, w1:45.23293879369905, w2:73.14910410326307, bias:-355.5593913927497, loss:17.26938819745534\n",
      "Epoch:359, w1:45.35816606642632, w2:73.35364955780852, bias:-356.5593913927497, loss:17.26938819745534\n",
      "Epoch:360, w1:45.483393339153594, w2:73.55819501235398, bias:-357.5593913927497, loss:17.26938819745534\n",
      "Epoch:361, w1:45.608620611880866, w2:73.76274046689943, bias:-358.5593913927497, loss:17.26938819745534\n",
      "Epoch:362, w1:45.73384788460814, w2:73.96728592144488, bias:-359.5593913927497, loss:17.26938819745534\n",
      "Epoch:363, w1:45.85907515733541, w2:74.17183137599034, bias:-360.5593913927497, loss:17.26938819745534\n",
      "Epoch:364, w1:45.984302430062684, w2:74.37637683053579, bias:-361.5593913927497, loss:17.26938819745534\n",
      "Epoch:365, w1:46.109529702789956, w2:74.58092228508124, bias:-362.5593913927497, loss:17.26938819745534\n",
      "Epoch:366, w1:46.23475697551723, w2:74.7854677396267, bias:-363.5593913927497, loss:17.26938819745534\n",
      "Epoch:367, w1:46.3599842482445, w2:74.99001319417215, bias:-364.5593913927497, loss:17.26938819745534\n",
      "Epoch:368, w1:46.485211520971774, w2:75.1945586487176, bias:-365.5593913927497, loss:17.26938819745534\n",
      "Epoch:369, w1:46.610438793699046, w2:75.39910410326306, bias:-366.5593913927497, loss:17.26938819745534\n",
      "Epoch:370, w1:46.73566606642632, w2:75.60364955780851, bias:-367.5593913927497, loss:17.26938819745534\n",
      "Epoch:371, w1:46.86089333915359, w2:75.80819501235396, bias:-368.5593913927497, loss:17.26938819745534\n",
      "Epoch:372, w1:46.986120611880864, w2:76.01274046689942, bias:-369.5593913927497, loss:17.26938819745534\n",
      "Epoch:373, w1:47.111347884608136, w2:76.21728592144487, bias:-370.5593913927497, loss:17.26938819745534\n",
      "Epoch:374, w1:47.23657515733541, w2:76.42183137599032, bias:-371.5593913927497, loss:17.26938819745534\n",
      "Epoch:375, w1:47.36180243006268, w2:76.62637683053578, bias:-372.5593913927497, loss:17.26938819745534\n",
      "Epoch:376, w1:47.487029702789954, w2:76.83092228508123, bias:-373.5593913927497, loss:17.26938819745534\n",
      "Epoch:377, w1:47.61225697551723, w2:77.03546773962668, bias:-374.5593913927497, loss:17.26938819745534\n",
      "Epoch:378, w1:47.7374842482445, w2:77.24001319417214, bias:-375.5593913927497, loss:17.26938819745534\n",
      "Epoch:379, w1:47.86271152097177, w2:77.44455864871759, bias:-376.5593913927497, loss:17.26938819745534\n",
      "Epoch:380, w1:47.987938793699044, w2:77.64910410326304, bias:-377.5593913927497, loss:17.26938819745534\n",
      "Epoch:381, w1:48.11316606642632, w2:77.8536495578085, bias:-378.5593913927497, loss:17.26938819745534\n",
      "Epoch:382, w1:48.23839333915359, w2:78.05819501235395, bias:-379.5593913927497, loss:17.26938819745534\n",
      "Epoch:383, w1:48.36362061188086, w2:78.2627404668994, bias:-380.5593913927497, loss:17.26938819745534\n",
      "Epoch:384, w1:48.488847884608134, w2:78.46728592144486, bias:-381.5593913927497, loss:17.26938819745534\n",
      "Epoch:385, w1:48.61407515733541, w2:78.67183137599031, bias:-382.5593913927497, loss:17.26938819745534\n",
      "Epoch:386, w1:48.73930243006268, w2:78.87637683053576, bias:-383.5593913927497, loss:17.26938819745534\n",
      "Epoch:387, w1:48.86452970278995, w2:79.08092228508121, bias:-384.5593913927497, loss:17.26938819745534\n",
      "Epoch:388, w1:48.989756975517224, w2:79.28546773962667, bias:-385.5593913927497, loss:17.26938819745534\n",
      "Epoch:389, w1:49.1149842482445, w2:79.49001319417212, bias:-386.5593913927497, loss:17.26938819745534\n",
      "Epoch:390, w1:49.24021152097177, w2:79.69455864871757, bias:-387.5593913927497, loss:17.26938819745534\n",
      "Epoch:391, w1:49.36543879369904, w2:79.89910410326303, bias:-388.5593913927497, loss:17.26938819745534\n",
      "Epoch:392, w1:49.490666066426314, w2:80.10364955780848, bias:-389.5593913927497, loss:17.26938819745534\n",
      "Epoch:393, w1:49.61589333915359, w2:80.30819501235393, bias:-390.5593913927497, loss:17.26938819745534\n",
      "Epoch:394, w1:49.74112061188086, w2:80.51274046689939, bias:-391.5593913927497, loss:17.26938819745534\n",
      "Epoch:395, w1:49.86634788460813, w2:80.71728592144484, bias:-392.5593913927497, loss:17.26938819745534\n",
      "Epoch:396, w1:49.991575157335404, w2:80.9218313759903, bias:-393.5593913927497, loss:17.26938819745534\n",
      "Epoch:397, w1:50.11680243006268, w2:81.12637683053575, bias:-394.5593913927497, loss:17.26938819745534\n",
      "Epoch:398, w1:50.24202970278995, w2:81.3309222850812, bias:-395.5593913927497, loss:17.26938819745534\n",
      "Epoch:399, w1:50.36725697551722, w2:81.53546773962665, bias:-396.5593913927497, loss:17.26938819745534\n",
      "Epoch:400, w1:50.492484248244494, w2:81.7400131941721, bias:-397.5593913927497, loss:17.26938819745534\n",
      "Epoch:401, w1:50.61771152097177, w2:81.94455864871756, bias:-398.5593913927497, loss:17.26938819745534\n",
      "Epoch:402, w1:50.74293879369904, w2:82.14910410326301, bias:-399.5593913927497, loss:17.26938819745534\n",
      "Epoch:403, w1:50.86816606642631, w2:82.35364955780847, bias:-400.5593913927497, loss:17.26938819745534\n",
      "Epoch:404, w1:50.993393339153585, w2:82.55819501235392, bias:-401.5593913927497, loss:17.26938819745534\n",
      "Epoch:405, w1:51.11862061188086, w2:82.76274046689937, bias:-402.5593913927497, loss:17.26938819745534\n",
      "Epoch:406, w1:51.24384788460813, w2:82.96728592144483, bias:-403.5593913927497, loss:17.26938819745534\n",
      "Epoch:407, w1:51.3690751573354, w2:83.17183137599028, bias:-404.5593913927497, loss:17.26938819745534\n",
      "Epoch:408, w1:51.494302430062675, w2:83.37637683053573, bias:-405.5593913927497, loss:17.26938819745534\n",
      "Epoch:409, w1:51.61952970278995, w2:83.58092228508119, bias:-406.5593913927497, loss:17.26938819745534\n",
      "Epoch:410, w1:51.74475697551722, w2:83.78546773962664, bias:-407.5593913927497, loss:17.26938819745534\n",
      "Epoch:411, w1:51.86998424824449, w2:83.99001319417209, bias:-408.5593913927497, loss:17.26938819745534\n",
      "Epoch:412, w1:51.995211520971765, w2:84.19455864871755, bias:-409.5593913927497, loss:17.26938819745534\n",
      "Epoch:413, w1:52.12043879369904, w2:84.399104103263, bias:-410.5593913927497, loss:17.26938819745534\n",
      "Epoch:414, w1:52.24566606642631, w2:84.60364955780845, bias:-411.5593913927497, loss:17.26938819745534\n",
      "Epoch:415, w1:52.37089333915358, w2:84.8081950123539, bias:-412.5593913927497, loss:17.26938819745534\n",
      "Epoch:416, w1:52.496120611880855, w2:85.01274046689936, bias:-413.5593913927497, loss:17.26938819745534\n",
      "Epoch:417, w1:52.62134788460813, w2:85.21728592144481, bias:-414.5593913927497, loss:17.26938819745534\n",
      "Epoch:418, w1:52.7465751573354, w2:85.42183137599027, bias:-415.5593913927497, loss:17.26938819745534\n",
      "Epoch:419, w1:52.87180243006267, w2:85.62637683053572, bias:-416.5593913927497, loss:17.26938819745534\n",
      "Epoch:420, w1:52.997029702789945, w2:85.83092228508117, bias:-417.5593913927497, loss:17.26938819745534\n",
      "Epoch:421, w1:53.12225697551722, w2:86.03546773962663, bias:-418.5593913927497, loss:17.26938819745534\n",
      "Epoch:422, w1:53.24748424824449, w2:86.24001319417208, bias:-419.5593913927497, loss:17.26938819745534\n",
      "Epoch:423, w1:53.37271152097176, w2:86.44455864871753, bias:-420.5593913927497, loss:17.26938819745534\n",
      "Epoch:424, w1:53.497938793699035, w2:86.64910410326299, bias:-421.5593913927497, loss:17.26938819745534\n",
      "Epoch:425, w1:53.62316606642631, w2:86.85364955780844, bias:-422.5593913927497, loss:17.26938819745534\n",
      "Epoch:426, w1:53.74839333915358, w2:87.05819501235389, bias:-423.5593913927497, loss:17.26938819745534\n",
      "Epoch:427, w1:53.87362061188085, w2:87.26274046689934, bias:-424.5593913927497, loss:17.26938819745534\n",
      "Epoch:428, w1:53.998847884608125, w2:87.4672859214448, bias:-425.5593913927497, loss:17.26938819745534\n",
      "Epoch:429, w1:54.1240751573354, w2:87.67183137599025, bias:-426.5593913927497, loss:17.26938819745534\n",
      "Epoch:430, w1:54.24930243006267, w2:87.8763768305357, bias:-427.5593913927497, loss:17.26938819745534\n",
      "Epoch:431, w1:54.37452970278994, w2:88.08092228508116, bias:-428.5593913927497, loss:17.26938819745534\n",
      "Epoch:432, w1:54.499756975517215, w2:88.28546773962661, bias:-429.5593913927497, loss:17.26938819745534\n",
      "Epoch:433, w1:54.62498424824449, w2:88.49001319417206, bias:-430.5593913927497, loss:17.26938819745534\n",
      "Epoch:434, w1:54.75021152097176, w2:88.69455864871752, bias:-431.5593913927497, loss:17.26938819745534\n",
      "Epoch:435, w1:54.87543879369903, w2:88.89910410326297, bias:-432.5593913927497, loss:17.26938819745534\n",
      "Epoch:436, w1:55.000666066426305, w2:89.10364955780842, bias:-433.5593913927497, loss:17.26938819745534\n",
      "Epoch:437, w1:55.12589333915358, w2:89.30819501235388, bias:-434.5593913927497, loss:17.26938819745534\n",
      "Epoch:438, w1:55.25112061188085, w2:89.51274046689933, bias:-435.5593913927497, loss:17.26938819745534\n",
      "Epoch:439, w1:55.37634788460812, w2:89.71728592144478, bias:-436.5593913927497, loss:17.26938819745534\n",
      "Epoch:440, w1:55.501575157335395, w2:89.92183137599024, bias:-437.5593913927497, loss:17.26938819745534\n",
      "Epoch:441, w1:55.62680243006267, w2:90.12637683053569, bias:-438.5593913927497, loss:17.26938819745534\n",
      "Epoch:442, w1:55.75202970278994, w2:90.33092228508114, bias:-439.5593913927497, loss:17.26938819745534\n",
      "Epoch:443, w1:55.87725697551721, w2:90.5354677396266, bias:-440.5593913927497, loss:17.26938819745534\n",
      "Epoch:444, w1:56.002484248244485, w2:90.74001319417205, bias:-441.5593913927497, loss:17.26938819745534\n",
      "Epoch:445, w1:56.12771152097176, w2:90.9445586487175, bias:-442.5593913927497, loss:17.26938819745534\n",
      "Epoch:446, w1:56.25293879369903, w2:91.14910410326296, bias:-443.5593913927497, loss:17.26938819745534\n",
      "Epoch:447, w1:56.3781660664263, w2:91.35364955780841, bias:-444.5593913927497, loss:17.26938819745534\n",
      "Epoch:448, w1:56.503393339153575, w2:91.55819501235386, bias:-445.5593913927497, loss:17.26938819745534\n",
      "Epoch:449, w1:56.62862061188085, w2:91.76274046689932, bias:-446.5593913927497, loss:17.26938819745534\n",
      "Epoch:450, w1:56.75384788460812, w2:91.96728592144477, bias:-447.5593913927497, loss:17.26938819745534\n",
      "Epoch:451, w1:56.87907515733539, w2:92.17183137599022, bias:-448.5593913927497, loss:17.26938819745534\n",
      "Epoch:452, w1:57.004302430062666, w2:92.37637683053568, bias:-449.5593913927497, loss:17.26938819745534\n",
      "Epoch:453, w1:57.12952970278994, w2:92.58092228508113, bias:-450.5593913927497, loss:17.26938819745534\n",
      "Epoch:454, w1:57.25475697551721, w2:92.78546773962658, bias:-451.5593913927497, loss:17.26938819745534\n",
      "Epoch:455, w1:57.37998424824448, w2:92.99001319417204, bias:-452.5593913927497, loss:17.26938819745534\n",
      "Epoch:456, w1:57.505211520971756, w2:93.19455864871749, bias:-453.5593913927497, loss:17.26938819745534\n",
      "Epoch:457, w1:57.63043879369903, w2:93.39910410326294, bias:-454.5593913927497, loss:17.26938819745534\n",
      "Epoch:458, w1:57.7556660664263, w2:93.6036495578084, bias:-455.5593913927497, loss:17.26938819745534\n",
      "Epoch:459, w1:57.88089333915357, w2:93.80819501235385, bias:-456.5593913927497, loss:17.26938819745534\n",
      "Epoch:460, w1:58.006120611880846, w2:94.0127404668993, bias:-457.5593913927497, loss:17.26938819745534\n",
      "Epoch:461, w1:58.13134788460812, w2:94.21728592144476, bias:-458.5593913927497, loss:17.26938819745534\n",
      "Epoch:462, w1:58.25657515733539, w2:94.42183137599021, bias:-459.5593913927497, loss:17.26938819745534\n",
      "Epoch:463, w1:58.38180243006266, w2:94.62637683053566, bias:-460.5593913927497, loss:17.26938819745534\n",
      "Epoch:464, w1:58.507029702789936, w2:94.83092228508112, bias:-461.5593913927497, loss:17.26938819745534\n",
      "Epoch:465, w1:58.63225697551721, w2:95.03546773962657, bias:-462.5593913927497, loss:17.26938819745534\n",
      "Epoch:466, w1:58.75748424824448, w2:95.24001319417202, bias:-463.5593913927497, loss:17.26938819745534\n",
      "Epoch:467, w1:58.88271152097175, w2:95.44455864871748, bias:-464.5593913927497, loss:17.26938819745534\n",
      "Epoch:468, w1:59.007938793699026, w2:95.64910410326293, bias:-465.5593913927497, loss:17.26938819745534\n",
      "Epoch:469, w1:59.1331660664263, w2:95.85364955780838, bias:-466.5593913927497, loss:17.26938819745534\n",
      "Epoch:470, w1:59.25839333915357, w2:96.05819501235383, bias:-467.5593913927497, loss:17.26938819745534\n",
      "Epoch:471, w1:59.38362061188084, w2:96.26274046689929, bias:-468.5593913927497, loss:17.26938819745534\n",
      "Epoch:472, w1:59.508847884608116, w2:96.46728592144474, bias:-469.5593913927497, loss:17.26938819745534\n",
      "Epoch:473, w1:59.63407515733539, w2:96.6718313759902, bias:-470.5593913927497, loss:17.26938819745534\n",
      "Epoch:474, w1:59.75930243006266, w2:96.87637683053565, bias:-471.5593913927497, loss:17.26938819745534\n",
      "Epoch:475, w1:59.88452970278993, w2:97.0809222850811, bias:-472.5593913927497, loss:17.26938819745534\n",
      "Epoch:476, w1:60.009756975517206, w2:97.28546773962655, bias:-473.5593913927497, loss:17.26938819745534\n",
      "Epoch:477, w1:60.13498424824448, w2:97.49001319417201, bias:-474.5593913927497, loss:17.26938819745534\n",
      "Epoch:478, w1:60.26021152097175, w2:97.69455864871746, bias:-475.5593913927497, loss:17.26938819745534\n",
      "Epoch:479, w1:60.385438793699024, w2:97.89910410326291, bias:-476.5593913927497, loss:17.26938819745534\n",
      "Epoch:480, w1:60.510666066426296, w2:98.10364955780837, bias:-477.5593913927497, loss:17.26938819745534\n",
      "Epoch:481, w1:60.63589333915357, w2:98.30819501235382, bias:-478.5593913927497, loss:17.26938819745534\n",
      "Epoch:482, w1:60.76112061188084, w2:98.51274046689927, bias:-479.5593913927497, loss:17.26938819745534\n",
      "Epoch:483, w1:60.886347884608114, w2:98.71728592144473, bias:-480.5593913927497, loss:17.26938819745534\n",
      "Epoch:484, w1:61.011575157335386, w2:98.92183137599018, bias:-481.5593913927497, loss:17.26938819745534\n",
      "Epoch:485, w1:61.13680243006266, w2:99.12637683053563, bias:-482.5593913927497, loss:17.26938819745534\n",
      "Epoch:486, w1:61.26202970278993, w2:99.33092228508109, bias:-483.5593913927497, loss:17.26938819745534\n",
      "Epoch:487, w1:61.387256975517204, w2:99.53546773962654, bias:-484.5593913927497, loss:17.26938819745534\n",
      "Epoch:488, w1:61.512484248244476, w2:99.740013194172, bias:-485.5593913927497, loss:17.26938819745534\n",
      "Epoch:489, w1:61.63771152097175, w2:99.94455864871745, bias:-486.5593913927497, loss:17.26938819745534\n",
      "Epoch:490, w1:61.76293879369902, w2:100.1491041032629, bias:-487.5593913927497, loss:17.26938819745534\n",
      "Epoch:491, w1:61.888166066426294, w2:100.35364955780835, bias:-488.5593913927497, loss:17.26938819745534\n",
      "Epoch:492, w1:62.013393339153566, w2:100.5581950123538, bias:-489.5593913927497, loss:17.26938819745534\n",
      "Epoch:493, w1:62.13862061188084, w2:100.76274046689926, bias:-490.5593913927497, loss:17.26938819745534\n",
      "Epoch:494, w1:62.26384788460811, w2:100.96728592144471, bias:-491.5593913927497, loss:17.26938819745534\n",
      "Epoch:495, w1:62.389075157335384, w2:101.17183137599017, bias:-492.5593913927497, loss:17.26938819745534\n",
      "Epoch:496, w1:62.514302430062656, w2:101.37637683053562, bias:-493.5593913927497, loss:17.26938819745534\n",
      "Epoch:497, w1:62.63952970278993, w2:101.58092228508107, bias:-494.5593913927497, loss:17.26938819745534\n",
      "Epoch:498, w1:62.7647569755172, w2:101.78546773962653, bias:-495.5593913927497, loss:17.26938819745534\n",
      "Epoch:499, w1:62.889984248244474, w2:101.99001319417198, bias:-496.5593913927497, loss:17.26938819745534\n",
      "Epoch:500, w1:63.01521152097175, w2:102.19455864871743, bias:-497.5593913927497, loss:17.26938819745534\n",
      "Epoch:501, w1:63.14043879369902, w2:102.39910410326289, bias:-498.5593913927497, loss:17.26938819745534\n",
      "Epoch:502, w1:63.26566606642629, w2:102.60364955780834, bias:-499.5593913927497, loss:17.26938819745534\n",
      "Epoch:503, w1:63.390893339153564, w2:102.80819501235379, bias:-500.5593913927497, loss:17.26938819745534\n",
      "Epoch:504, w1:63.51612061188084, w2:103.01274046689925, bias:-501.5593913927497, loss:17.26938819745534\n",
      "Epoch:505, w1:63.64134788460811, w2:103.2172859214447, bias:-502.5593913927497, loss:17.26938819745534\n",
      "Epoch:506, w1:63.76657515733538, w2:103.42183137599015, bias:-503.5593913927497, loss:17.26938819745534\n",
      "Epoch:507, w1:63.891802430062654, w2:103.6263768305356, bias:-504.5593913927497, loss:17.26938819745534\n",
      "Epoch:508, w1:64.01702970278993, w2:103.83092228508106, bias:-505.5593913927497, loss:17.26938819745534\n",
      "Epoch:509, w1:64.1422569755172, w2:104.03546773962651, bias:-506.5593913927497, loss:17.26938819745534\n",
      "Epoch:510, w1:64.26748424824447, w2:104.24001319417196, bias:-507.5593913927497, loss:17.26938819745534\n",
      "Epoch:511, w1:64.39271152097174, w2:104.44455864871742, bias:-508.5593913927497, loss:17.26938819745534\n",
      "Epoch:512, w1:64.51793879369902, w2:104.64910410326287, bias:-509.5593913927497, loss:17.26938819745534\n",
      "Epoch:513, w1:64.64316606642629, w2:104.85364955780832, bias:-510.5593913927497, loss:17.26938819745534\n",
      "Epoch:514, w1:64.76839333915356, w2:105.05819501235378, bias:-511.5593913927497, loss:17.26938819745534\n",
      "Epoch:515, w1:64.89362061188083, w2:105.26274046689923, bias:-512.5593913927497, loss:17.26938819745534\n",
      "Epoch:516, w1:65.0188478846081, w2:105.46728592144468, bias:-513.5593913927497, loss:17.26938819745534\n",
      "Epoch:517, w1:65.14407515733538, w2:105.67183137599014, bias:-514.5593913927497, loss:17.26938819745534\n",
      "Epoch:518, w1:65.26930243006265, w2:105.87637683053559, bias:-515.5593913927497, loss:17.26938819745534\n",
      "Epoch:519, w1:65.39452970278992, w2:106.08092228508104, bias:-516.5593913927497, loss:17.26938819745534\n",
      "Epoch:520, w1:65.5197569755172, w2:106.2854677396265, bias:-517.5593913927497, loss:17.26938819745534\n",
      "Epoch:521, w1:65.64498424824447, w2:106.49001319417195, bias:-518.5593913927497, loss:17.26938819745534\n",
      "Epoch:522, w1:65.77021152097174, w2:106.6945586487174, bias:-519.5593913927497, loss:17.26938819745534\n",
      "Epoch:523, w1:65.89543879369901, w2:106.89910410326286, bias:-520.5593913927497, loss:17.26938819745534\n",
      "Epoch:524, w1:66.02066606642629, w2:107.10364955780831, bias:-521.5593913927497, loss:17.26938819745534\n",
      "Epoch:525, w1:66.14589333915356, w2:107.30819501235376, bias:-522.5593913927497, loss:17.26938819745534\n",
      "Epoch:526, w1:66.27112061188083, w2:107.51274046689922, bias:-523.5593913927497, loss:17.26938819745534\n",
      "Epoch:527, w1:66.3963478846081, w2:107.71728592144467, bias:-524.5593913927497, loss:17.26938819745534\n",
      "Epoch:528, w1:66.52157515733538, w2:107.92183137599012, bias:-525.5593913927497, loss:17.26938819745534\n",
      "Epoch:529, w1:66.64680243006265, w2:108.12637683053558, bias:-526.5593913927497, loss:17.26938819745534\n",
      "Epoch:530, w1:66.77202970278992, w2:108.33092228508103, bias:-527.5593913927497, loss:17.26938819745534\n",
      "Epoch:531, w1:66.8972569755172, w2:108.53546773962648, bias:-528.5593913927497, loss:17.26938819745534\n",
      "Epoch:532, w1:67.02248424824447, w2:108.74001319417194, bias:-529.5593913927497, loss:17.26938819745534\n",
      "Epoch:533, w1:67.14771152097174, w2:108.94455864871739, bias:-530.5593913927497, loss:17.26938819745534\n",
      "Epoch:534, w1:67.27293879369901, w2:109.14910410326284, bias:-531.5593913927497, loss:17.26938819745534\n",
      "Epoch:535, w1:67.39816606642628, w2:109.3536495578083, bias:-532.5593913927497, loss:17.26938819745534\n",
      "Epoch:536, w1:67.52339333915356, w2:109.55819501235375, bias:-533.5593913927497, loss:17.26938819745534\n",
      "Epoch:537, w1:67.64862061188083, w2:109.7627404668992, bias:-534.5593913927497, loss:17.26938819745534\n",
      "Epoch:538, w1:67.7738478846081, w2:109.96728592144466, bias:-535.5593913927497, loss:17.26938819745534\n",
      "Epoch:539, w1:67.89907515733537, w2:110.17183137599011, bias:-536.5593913927497, loss:17.26938819745534\n",
      "Epoch:540, w1:68.02430243006265, w2:110.37637683053556, bias:-537.5593913927497, loss:17.26938819745534\n",
      "Epoch:541, w1:68.14952970278992, w2:110.58092228508102, bias:-538.5593913927497, loss:17.26938819745534\n",
      "Epoch:542, w1:68.27475697551719, w2:110.78546773962647, bias:-539.5593913927497, loss:17.26938819745534\n",
      "Epoch:543, w1:68.39998424824446, w2:110.99001319417192, bias:-540.5593913927497, loss:17.26938819745534\n",
      "Epoch:544, w1:68.52521152097174, w2:111.19455864871738, bias:-541.5593913927497, loss:17.26938819745534\n",
      "Epoch:545, w1:68.65043879369901, w2:111.39910410326283, bias:-542.5593913927497, loss:17.26938819745534\n",
      "Epoch:546, w1:68.77566606642628, w2:111.60364955780828, bias:-543.5593913927497, loss:17.26938819745534\n",
      "Epoch:547, w1:68.90089333915355, w2:111.80819501235374, bias:-544.5593913927497, loss:17.26938819745534\n",
      "Epoch:548, w1:69.02612061188083, w2:112.01274046689919, bias:-545.5593913927497, loss:17.26938819745534\n",
      "Epoch:549, w1:69.1513478846081, w2:112.21728592144464, bias:-546.5593913927497, loss:17.26938819745534\n",
      "Epoch:550, w1:69.27657515733537, w2:112.4218313759901, bias:-547.5593913927497, loss:17.26938819745534\n",
      "Epoch:551, w1:69.40180243006265, w2:112.62637683053555, bias:-548.5593913927497, loss:17.26938819745534\n",
      "Epoch:552, w1:69.52702970278992, w2:112.830922285081, bias:-549.5593913927497, loss:17.26938819745534\n",
      "Epoch:553, w1:69.65225697551719, w2:113.03546773962645, bias:-550.5593913927497, loss:17.26938819745534\n",
      "Epoch:554, w1:69.77748424824446, w2:113.24001319417191, bias:-551.5593913927497, loss:17.26938819745534\n",
      "Epoch:555, w1:69.90271152097174, w2:113.44455864871736, bias:-552.5593913927497, loss:17.26938819745534\n",
      "Epoch:556, w1:70.02793879369901, w2:113.64910410326281, bias:-553.5593913927497, loss:17.26938819745534\n",
      "Epoch:557, w1:70.15316606642628, w2:113.85364955780827, bias:-554.5593913927497, loss:17.26938819745534\n",
      "Epoch:558, w1:70.27839333915355, w2:114.05819501235372, bias:-555.5593913927497, loss:17.26938819745534\n",
      "Epoch:559, w1:70.40362061188083, w2:114.26274046689917, bias:-556.5593913927497, loss:17.26938819745534\n",
      "Epoch:560, w1:70.5288478846081, w2:114.46728592144463, bias:-557.5593913927497, loss:17.26938819745534\n",
      "Epoch:561, w1:70.65407515733537, w2:114.67183137599008, bias:-558.5593913927497, loss:17.26938819745534\n",
      "Epoch:562, w1:70.77930243006264, w2:114.87637683053553, bias:-559.5593913927497, loss:17.26938819745534\n",
      "Epoch:563, w1:70.90452970278992, w2:115.08092228508099, bias:-560.5593913927497, loss:17.26938819745534\n",
      "Epoch:564, w1:71.02975697551719, w2:115.28546773962644, bias:-561.5593913927497, loss:17.26938819745534\n",
      "Epoch:565, w1:71.15498424824446, w2:115.4900131941719, bias:-562.5593913927497, loss:17.26938819745534\n",
      "Epoch:566, w1:71.28021152097173, w2:115.69455864871735, bias:-563.5593913927497, loss:17.26938819745534\n",
      "Epoch:567, w1:71.405438793699, w2:115.8991041032628, bias:-564.5593913927497, loss:17.26938819745534\n",
      "Epoch:568, w1:71.53066606642628, w2:116.10364955780825, bias:-565.5593913927497, loss:17.26938819745534\n",
      "Epoch:569, w1:71.65589333915355, w2:116.3081950123537, bias:-566.5593913927497, loss:17.26938819745534\n",
      "Epoch:570, w1:71.78112061188082, w2:116.51274046689916, bias:-567.5593913927497, loss:17.26938819745534\n",
      "Epoch:571, w1:71.9063478846081, w2:116.71728592144461, bias:-568.5593913927497, loss:17.26938819745534\n",
      "Epoch:572, w1:72.03157515733537, w2:116.92183137599007, bias:-569.5593913927497, loss:17.26938819745534\n",
      "Epoch:573, w1:72.15680243006264, w2:117.12637683053552, bias:-570.5593913927497, loss:17.26938819745534\n",
      "Epoch:574, w1:72.28202970278991, w2:117.33092228508097, bias:-571.5593913927497, loss:17.26938819745534\n",
      "Epoch:575, w1:72.40725697551719, w2:117.53546773962643, bias:-572.5593913927497, loss:17.26938819745534\n",
      "Epoch:576, w1:72.53248424824446, w2:117.74001319417188, bias:-573.5593913927497, loss:17.26938819745534\n",
      "Epoch:577, w1:72.65771152097173, w2:117.94455864871733, bias:-574.5593913927497, loss:17.26938819745534\n",
      "Epoch:578, w1:72.782938793699, w2:118.14910410326279, bias:-575.5593913927497, loss:17.26938819745534\n",
      "Epoch:579, w1:72.90816606642628, w2:118.35364955780824, bias:-576.5593913927497, loss:17.26938819745534\n",
      "Epoch:580, w1:73.03339333915355, w2:118.55819501235369, bias:-577.5593913927497, loss:17.26938819745534\n",
      "Epoch:581, w1:73.15862061188082, w2:118.76274046689915, bias:-578.5593913927497, loss:17.26938819745534\n",
      "Epoch:582, w1:73.2838478846081, w2:118.9672859214446, bias:-579.5593913927497, loss:17.26938819745534\n",
      "Epoch:583, w1:73.40907515733537, w2:119.17183137599005, bias:-580.5593913927497, loss:17.26938819745534\n",
      "Epoch:584, w1:73.53430243006264, w2:119.3763768305355, bias:-581.5593913927497, loss:17.26938819745534\n",
      "Epoch:585, w1:73.65952970278991, w2:119.58092228508096, bias:-582.5593913927497, loss:17.26938819745534\n",
      "Epoch:586, w1:73.78475697551718, w2:119.78546773962641, bias:-583.5593913927497, loss:17.26938819745534\n",
      "Epoch:587, w1:73.90998424824446, w2:119.99001319417187, bias:-584.5593913927497, loss:17.26938819745534\n",
      "Epoch:588, w1:74.03521152097173, w2:120.19455864871732, bias:-585.5593913927497, loss:17.26938819745534\n",
      "Epoch:589, w1:74.160438793699, w2:120.39910410326277, bias:-586.5593913927497, loss:17.26938819745534\n",
      "Epoch:590, w1:74.28566606642627, w2:120.60364955780823, bias:-587.5593913927497, loss:17.26938819745534\n",
      "Epoch:591, w1:74.41089333915355, w2:120.80819501235368, bias:-588.5593913927497, loss:17.26938819745534\n",
      "Epoch:592, w1:74.53612061188082, w2:121.01274046689913, bias:-589.5593913927497, loss:17.26938819745534\n",
      "Epoch:593, w1:74.66134788460809, w2:121.21728592144459, bias:-590.5593913927497, loss:17.26938819745534\n",
      "Epoch:594, w1:74.78657515733536, w2:121.42183137599004, bias:-591.5593913927497, loss:17.26938819745534\n",
      "Epoch:595, w1:74.91180243006264, w2:121.62637683053549, bias:-592.5593913927497, loss:17.26938819745534\n",
      "Epoch:596, w1:75.03702970278991, w2:121.83092228508094, bias:-593.5593913927497, loss:17.26938819745534\n",
      "Epoch:597, w1:75.16225697551718, w2:122.0354677396264, bias:-594.5593913927497, loss:17.26938819745534\n",
      "Epoch:598, w1:75.28748424824445, w2:122.24001319417185, bias:-595.5593913927497, loss:17.26938819745534\n",
      "Epoch:599, w1:75.41271152097173, w2:122.4445586487173, bias:-596.5593913927497, loss:17.26938819745534\n",
      "Epoch:600, w1:75.537938793699, w2:122.64910410326276, bias:-597.5593913927497, loss:17.26938819745534\n",
      "Epoch:601, w1:75.66316606642627, w2:122.85364955780821, bias:-598.5593913927497, loss:17.26938819745534\n",
      "Epoch:602, w1:75.78839333915354, w2:123.05819501235366, bias:-599.5593913927497, loss:17.26938819745534\n",
      "Epoch:603, w1:75.91362061188082, w2:123.26274046689912, bias:-600.5593913927497, loss:17.26938819745534\n",
      "Epoch:604, w1:76.03884788460809, w2:123.46728592144457, bias:-601.5593913927497, loss:17.26938819745534\n",
      "Epoch:605, w1:76.16407515733536, w2:123.67183137599002, bias:-602.5593913927497, loss:17.26938819745534\n",
      "Epoch:606, w1:76.28930243006263, w2:123.87637683053548, bias:-603.5593913927497, loss:17.26938819745534\n",
      "Epoch:607, w1:76.4145297027899, w2:124.08092228508093, bias:-604.5593913927497, loss:17.26938819745534\n",
      "Epoch:608, w1:76.53975697551718, w2:124.28546773962638, bias:-605.5593913927497, loss:17.26938819745534\n",
      "Epoch:609, w1:76.66498424824445, w2:124.49001319417184, bias:-606.5593913927497, loss:17.26938819745534\n",
      "Epoch:610, w1:76.79021152097172, w2:124.69455864871729, bias:-607.5593913927497, loss:17.26938819745534\n",
      "Epoch:611, w1:76.915438793699, w2:124.89910410326274, bias:-608.5593913927497, loss:17.26938819745534\n",
      "Epoch:612, w1:77.04066606642627, w2:125.1036495578082, bias:-609.5593913927497, loss:17.26938819745534\n",
      "Epoch:613, w1:77.16589333915354, w2:125.30819501235365, bias:-610.5593913927497, loss:17.26938819745534\n",
      "Epoch:614, w1:77.29112061188081, w2:125.5127404668991, bias:-611.5593913927497, loss:17.26938819745534\n",
      "Epoch:615, w1:77.41634788460809, w2:125.71728592144456, bias:-612.5593913927497, loss:17.26938819745534\n",
      "Epoch:616, w1:77.54157515733536, w2:125.92183137599001, bias:-613.5593913927497, loss:17.26938819745534\n",
      "Epoch:617, w1:77.66680243006263, w2:126.12637683053546, bias:-614.5593913927497, loss:17.26938819745534\n",
      "Epoch:618, w1:77.7920297027899, w2:126.33092228508092, bias:-615.5593913927497, loss:17.26938819745534\n",
      "Epoch:619, w1:77.91725697551718, w2:126.53546773962637, bias:-616.5593913927497, loss:17.26938819745534\n",
      "Epoch:620, w1:78.04248424824445, w2:126.74001319417182, bias:-617.5593913927497, loss:17.26938819745534\n",
      "Epoch:621, w1:78.16771152097172, w2:126.94455864871728, bias:-618.5593913927497, loss:17.26938819745534\n",
      "Epoch:622, w1:78.292938793699, w2:127.14910410326273, bias:-619.5593913927497, loss:17.26938819745534\n",
      "Epoch:623, w1:78.41816606642627, w2:127.35364955780818, bias:-620.5593913927497, loss:17.26938819745534\n",
      "Epoch:624, w1:78.54339333915354, w2:127.55819501235364, bias:-621.5593913927497, loss:17.26938819745534\n",
      "Epoch:625, w1:78.66862061188081, w2:127.76274046689909, bias:-622.5593913927497, loss:17.26938819745534\n",
      "Epoch:626, w1:78.79384788460808, w2:127.96728592144454, bias:-623.5593913927497, loss:17.26938819745534\n",
      "Epoch:627, w1:78.91907515733536, w2:128.17183137599, bias:-624.5593913927497, loss:17.26938819745534\n",
      "Epoch:628, w1:79.04430243006263, w2:128.37637683053546, bias:-625.5593913927497, loss:17.26938819745534\n",
      "Epoch:629, w1:79.1695297027899, w2:128.58092228508093, bias:-626.5593913927497, loss:17.26938819745534\n",
      "Epoch:630, w1:79.29475697551717, w2:128.7854677396264, bias:-627.5593913927497, loss:17.26938819745534\n",
      "Epoch:631, w1:79.41998424824445, w2:128.99001319417187, bias:-628.5593913927497, loss:17.26938819745534\n",
      "Epoch:632, w1:79.54521152097172, w2:129.19455864871733, bias:-629.5593913927497, loss:17.26938819745534\n",
      "Epoch:633, w1:79.67043879369899, w2:129.3991041032628, bias:-630.5593913927497, loss:17.26938819745534\n",
      "Epoch:634, w1:79.79566606642626, w2:129.60364955780827, bias:-631.5593913927497, loss:17.26938819745534\n",
      "Epoch:635, w1:79.92089333915354, w2:129.80819501235374, bias:-632.5593913927497, loss:17.26938819745534\n",
      "Epoch:636, w1:80.04612061188081, w2:130.0127404668992, bias:-633.5593913927497, loss:17.26938819745534\n",
      "Epoch:637, w1:80.17134788460808, w2:130.21728592144467, bias:-634.5593913927497, loss:17.26938819745534\n",
      "Epoch:638, w1:80.29657515733535, w2:130.42183137599014, bias:-635.5593913927497, loss:17.26938819745534\n",
      "Epoch:639, w1:80.42180243006263, w2:130.6263768305356, bias:-636.5593913927497, loss:17.26938819745534\n",
      "Epoch:640, w1:80.5470297027899, w2:130.83092228508107, bias:-637.5593913927497, loss:17.26938819745534\n",
      "Epoch:641, w1:80.67225697551717, w2:131.03546773962654, bias:-638.5593913927497, loss:17.26938819745534\n",
      "Epoch:642, w1:80.79748424824444, w2:131.240013194172, bias:-639.5593913927497, loss:17.26938819745534\n",
      "Epoch:643, w1:80.92271152097172, w2:131.44455864871748, bias:-640.5593913927497, loss:17.26938819745534\n",
      "Epoch:644, w1:81.04793879369899, w2:131.64910410326294, bias:-641.5593913927497, loss:17.26938819745534\n",
      "Epoch:645, w1:81.17316606642626, w2:131.8536495578084, bias:-642.5593913927497, loss:17.26938819745534\n",
      "Epoch:646, w1:81.29839333915353, w2:132.05819501235388, bias:-643.5593913927497, loss:17.26938819745534\n",
      "Epoch:647, w1:81.4236206118808, w2:132.26274046689934, bias:-644.5593913927497, loss:17.26938819745534\n",
      "Epoch:648, w1:81.54884788460808, w2:132.4672859214448, bias:-645.5593913927497, loss:17.26938819745534\n",
      "Epoch:649, w1:81.67407515733535, w2:132.67183137599028, bias:-646.5593913927497, loss:17.26938819745534\n",
      "Epoch:650, w1:81.79930243006262, w2:132.87637683053575, bias:-647.5593913927497, loss:17.26938819745534\n",
      "Epoch:651, w1:81.9245297027899, w2:133.08092228508121, bias:-648.5593913927497, loss:17.26938819745534\n",
      "Epoch:652, w1:82.04975697551717, w2:133.28546773962668, bias:-649.5593913927497, loss:17.26938819745534\n",
      "Epoch:653, w1:82.17498424824444, w2:133.49001319417215, bias:-650.5593913927497, loss:17.26938819745534\n",
      "Epoch:654, w1:82.30021152097171, w2:133.69455864871762, bias:-651.5593913927497, loss:17.26938819745534\n",
      "Epoch:655, w1:82.42543879369899, w2:133.89910410326308, bias:-652.5593913927497, loss:17.26938819745534\n",
      "Epoch:656, w1:82.55066606642626, w2:134.10364955780855, bias:-653.5593913927497, loss:17.26938819745534\n",
      "Epoch:657, w1:82.67589333915353, w2:134.30819501235402, bias:-654.5593913927497, loss:17.26938819745534\n",
      "Epoch:658, w1:82.8011206118808, w2:134.5127404668995, bias:-655.5593913927497, loss:17.26938819745534\n",
      "Epoch:659, w1:82.92634788460808, w2:134.71728592144495, bias:-656.5593913927497, loss:17.26938819745534\n",
      "Epoch:660, w1:83.05157515733535, w2:134.92183137599042, bias:-657.5593913927497, loss:17.26938819745534\n",
      "Epoch:661, w1:83.17680243006262, w2:135.1263768305359, bias:-658.5593913927497, loss:17.26938819745534\n",
      "Epoch:662, w1:83.3020297027899, w2:135.33092228508136, bias:-659.5593913927497, loss:17.26938819745534\n",
      "Epoch:663, w1:83.42725697551717, w2:135.53546773962682, bias:-660.5593913927497, loss:17.26938819745534\n",
      "Epoch:664, w1:83.55248424824444, w2:135.7400131941723, bias:-661.5593913927497, loss:17.26938819745534\n",
      "Epoch:665, w1:83.67771152097171, w2:135.94455864871776, bias:-662.5593913927497, loss:17.26938819745534\n",
      "Epoch:666, w1:83.80293879369898, w2:136.14910410326323, bias:-663.5593913927497, loss:17.26938819745534\n",
      "Epoch:667, w1:83.92816606642626, w2:136.3536495578087, bias:-664.5593913927497, loss:17.26938819745534\n",
      "Epoch:668, w1:84.05339333915353, w2:136.55819501235416, bias:-665.5593913927497, loss:17.26938819745534\n",
      "Epoch:669, w1:84.1786206118808, w2:136.76274046689963, bias:-666.5593913927497, loss:17.26938819745534\n",
      "Epoch:670, w1:84.30384788460807, w2:136.9672859214451, bias:-667.5593913927497, loss:17.26938819745534\n",
      "Epoch:671, w1:84.42907515733535, w2:137.17183137599056, bias:-668.5593913927497, loss:17.26938819745534\n",
      "Epoch:672, w1:84.55430243006262, w2:137.37637683053603, bias:-669.5593913927497, loss:17.26938819745534\n",
      "Epoch:673, w1:84.67952970278989, w2:137.5809222850815, bias:-670.5593913927497, loss:17.26938819745534\n",
      "Epoch:674, w1:84.80475697551717, w2:137.78546773962697, bias:-671.5593913927497, loss:17.26938819745534\n",
      "Epoch:675, w1:84.92998424824444, w2:137.99001319417243, bias:-672.5593913927497, loss:17.26938819745534\n",
      "Epoch:676, w1:85.05521152097171, w2:138.1945586487179, bias:-673.5593913927497, loss:17.26938819745534\n",
      "Epoch:677, w1:85.18043879369898, w2:138.39910410326337, bias:-674.5593913927497, loss:17.26938819745534\n",
      "Epoch:678, w1:85.30566606642626, w2:138.60364955780884, bias:-675.5593913927497, loss:17.26938819745534\n",
      "Epoch:679, w1:85.43089333915353, w2:138.8081950123543, bias:-676.5593913927497, loss:17.26938819745534\n",
      "Epoch:680, w1:85.5561206118808, w2:139.01274046689977, bias:-677.5593913927497, loss:17.26938819745534\n",
      "Epoch:681, w1:85.68134788460807, w2:139.21728592144524, bias:-678.5593913927497, loss:17.26938819745534\n",
      "Epoch:682, w1:85.80657515733535, w2:139.4218313759907, bias:-679.5593913927497, loss:17.26938819745534\n",
      "Epoch:683, w1:85.93180243006262, w2:139.62637683053617, bias:-680.5593913927497, loss:17.26938819745534\n",
      "Epoch:684, w1:86.05702970278989, w2:139.83092228508164, bias:-681.5593913927497, loss:17.26938819745534\n",
      "Epoch:685, w1:86.18225697551716, w2:140.0354677396271, bias:-682.5593913927497, loss:17.26938819745534\n",
      "Epoch:686, w1:86.30748424824444, w2:140.24001319417258, bias:-683.5593913927497, loss:17.26938819745534\n",
      "Epoch:687, w1:86.43271152097171, w2:140.44455864871804, bias:-684.5593913927497, loss:17.26938819745534\n",
      "Epoch:688, w1:86.55793879369898, w2:140.6491041032635, bias:-685.5593913927497, loss:17.26938819745534\n",
      "Epoch:689, w1:86.68316606642625, w2:140.85364955780898, bias:-686.5593913927497, loss:17.26938819745534\n",
      "Epoch:690, w1:86.80839333915353, w2:141.05819501235445, bias:-687.5593913927497, loss:17.26938819745534\n",
      "Epoch:691, w1:86.9336206118808, w2:141.2627404668999, bias:-688.5593913927497, loss:17.26938819745534\n",
      "Epoch:692, w1:87.05884788460807, w2:141.46728592144538, bias:-689.5593913927497, loss:17.26938819745534\n",
      "Epoch:693, w1:87.18407515733534, w2:141.67183137599085, bias:-690.5593913927497, loss:17.26938819745534\n",
      "Epoch:694, w1:87.30930243006262, w2:141.87637683053632, bias:-691.5593913927497, loss:17.26938819745534\n",
      "Epoch:695, w1:87.43452970278989, w2:142.08092228508178, bias:-692.5593913927497, loss:17.26938819745534\n",
      "Epoch:696, w1:87.55975697551716, w2:142.28546773962725, bias:-693.5593913927497, loss:17.26938819745534\n",
      "Epoch:697, w1:87.68498424824443, w2:142.49001319417272, bias:-694.5593913927497, loss:17.26938819745534\n",
      "Epoch:698, w1:87.8102115209717, w2:142.69455864871819, bias:-695.5593913927497, loss:17.26938819745534\n",
      "Epoch:699, w1:87.93543879369898, w2:142.89910410326365, bias:-696.5593913927497, loss:17.26938819745534\n",
      "Epoch:700, w1:88.06066606642625, w2:143.10364955780912, bias:-697.5593913927497, loss:17.26938819745534\n",
      "Epoch:701, w1:88.18589333915352, w2:143.3081950123546, bias:-698.5593913927497, loss:17.26938819745534\n",
      "Epoch:702, w1:88.3111206118808, w2:143.51274046690006, bias:-699.5593913927497, loss:17.26938819745534\n",
      "Epoch:703, w1:88.43634788460807, w2:143.71728592144552, bias:-700.5593913927497, loss:17.26938819745534\n",
      "Epoch:704, w1:88.56157515733534, w2:143.921831375991, bias:-701.5593913927497, loss:17.26938819745534\n",
      "Epoch:705, w1:88.68680243006261, w2:144.12637683053646, bias:-702.5593913927497, loss:17.26938819745534\n",
      "Epoch:706, w1:88.81202970278989, w2:144.33092228508193, bias:-703.5593913927497, loss:17.26938819745534\n",
      "Epoch:707, w1:88.93725697551716, w2:144.5354677396274, bias:-704.5593913927497, loss:17.26938819745534\n",
      "Epoch:708, w1:89.06248424824443, w2:144.74001319417286, bias:-705.5593913927497, loss:17.26938819745534\n",
      "Epoch:709, w1:89.1877115209717, w2:144.94455864871833, bias:-706.5593913927497, loss:17.26938819745534\n",
      "Epoch:710, w1:89.31293879369898, w2:145.1491041032638, bias:-707.5593913927497, loss:17.26938819745534\n",
      "Epoch:711, w1:89.43816606642625, w2:145.35364955780926, bias:-708.5593913927497, loss:17.26938819745534\n",
      "Epoch:712, w1:89.56339333915352, w2:145.55819501235473, bias:-709.5593913927497, loss:17.26938819745534\n",
      "Epoch:713, w1:89.6886206118808, w2:145.7627404669002, bias:-710.5593913927497, loss:17.26938819745534\n",
      "Epoch:714, w1:89.81384788460807, w2:145.96728592144567, bias:-711.5593913927497, loss:17.26938819745534\n",
      "Epoch:715, w1:89.93907515733534, w2:146.17183137599113, bias:-712.5593913927497, loss:17.26938819745534\n",
      "Epoch:716, w1:90.06430243006261, w2:146.3763768305366, bias:-713.5593913927497, loss:17.26938819745534\n",
      "Epoch:717, w1:90.18952970278988, w2:146.58092228508207, bias:-714.5593913927497, loss:17.26938819745534\n",
      "Epoch:718, w1:90.31475697551716, w2:146.78546773962753, bias:-715.5593913927497, loss:17.26938819745534\n",
      "Epoch:719, w1:90.43998424824443, w2:146.990013194173, bias:-716.5593913927497, loss:17.26938819745534\n",
      "Epoch:720, w1:90.5652115209717, w2:147.19455864871847, bias:-717.5593913927497, loss:17.26938819745534\n",
      "Epoch:721, w1:90.69043879369897, w2:147.39910410326394, bias:-718.5593913927497, loss:17.26938819745534\n",
      "Epoch:722, w1:90.81566606642625, w2:147.6036495578094, bias:-719.5593913927497, loss:17.26938819745534\n",
      "Epoch:723, w1:90.94089333915352, w2:147.80819501235487, bias:-720.5593913927497, loss:17.26938819745534\n",
      "Epoch:724, w1:91.06612061188079, w2:148.01274046690034, bias:-721.5593913927497, loss:17.26938819745534\n",
      "Epoch:725, w1:91.19134788460806, w2:148.2172859214458, bias:-722.5593913927497, loss:17.26938819745534\n",
      "Epoch:726, w1:91.31657515733534, w2:148.42183137599127, bias:-723.5593913927497, loss:17.26938819745534\n",
      "Epoch:727, w1:91.44180243006261, w2:148.62637683053674, bias:-724.5593913927497, loss:17.26938819745534\n",
      "Epoch:728, w1:91.56702970278988, w2:148.8309222850822, bias:-725.5593913927497, loss:17.26938819745534\n",
      "Epoch:729, w1:91.69225697551715, w2:149.03546773962768, bias:-726.5593913927497, loss:17.26938819745534\n",
      "Epoch:730, w1:91.81748424824443, w2:149.24001319417314, bias:-727.5593913927497, loss:17.26938819745534\n",
      "Epoch:731, w1:91.9427115209717, w2:149.4445586487186, bias:-728.5593913927497, loss:17.26938819745534\n",
      "Epoch:732, w1:92.06793879369897, w2:149.64910410326408, bias:-729.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:733, w1:92.19316606642624, w2:149.85364955780955, bias:-730.5593913927497, loss:17.26938819745534\n",
      "Epoch:734, w1:92.31839333915352, w2:150.05819501235501, bias:-731.5593913927497, loss:17.26938819745534\n",
      "Epoch:735, w1:92.44362061188079, w2:150.26274046690048, bias:-732.5593913927497, loss:17.26938819745534\n",
      "Epoch:736, w1:92.56884788460806, w2:150.46728592144595, bias:-733.5593913927497, loss:17.26938819745534\n",
      "Epoch:737, w1:92.69407515733533, w2:150.67183137599142, bias:-734.5593913927497, loss:17.26938819745534\n",
      "Epoch:738, w1:92.8193024300626, w2:150.87637683053688, bias:-735.5593913927497, loss:17.26938819745534\n",
      "Epoch:739, w1:92.94452970278988, w2:151.08092228508235, bias:-736.5593913927497, loss:17.26938819745534\n",
      "Epoch:740, w1:93.06975697551715, w2:151.28546773962782, bias:-737.5593913927497, loss:17.26938819745534\n",
      "Epoch:741, w1:93.19498424824442, w2:151.4900131941733, bias:-738.5593913927497, loss:17.26938819745534\n",
      "Epoch:742, w1:93.3202115209717, w2:151.69455864871875, bias:-739.5593913927497, loss:17.26938819745534\n",
      "Epoch:743, w1:93.44543879369897, w2:151.89910410326422, bias:-740.5593913927497, loss:17.26938819745534\n",
      "Epoch:744, w1:93.57066606642624, w2:152.1036495578097, bias:-741.5593913927497, loss:17.26938819745534\n",
      "Epoch:745, w1:93.69589333915351, w2:152.30819501235516, bias:-742.5593913927497, loss:17.26938819745534\n",
      "Epoch:746, w1:93.82112061188079, w2:152.51274046690062, bias:-743.5593913927497, loss:17.26938819745534\n",
      "Epoch:747, w1:93.94634788460806, w2:152.7172859214461, bias:-744.5593913927497, loss:17.26938819745534\n",
      "Epoch:748, w1:94.07157515733533, w2:152.92183137599156, bias:-745.5593913927497, loss:17.26938819745534\n",
      "Epoch:749, w1:94.1968024300626, w2:153.12637683053703, bias:-746.5593913927497, loss:17.26938819745534\n",
      "Epoch:750, w1:94.32202970278988, w2:153.3309222850825, bias:-747.5593913927497, loss:17.26938819745534\n",
      "Epoch:751, w1:94.44725697551715, w2:153.53546773962796, bias:-748.5593913927497, loss:17.26938819745534\n",
      "Epoch:752, w1:94.57248424824442, w2:153.74001319417343, bias:-749.5593913927497, loss:17.26938819745534\n",
      "Epoch:753, w1:94.6977115209717, w2:153.9445586487189, bias:-750.5593913927497, loss:17.26938819745534\n",
      "Epoch:754, w1:94.82293879369897, w2:154.14910410326436, bias:-751.5593913927497, loss:17.26938819745534\n",
      "Epoch:755, w1:94.94816606642624, w2:154.35364955780983, bias:-752.5593913927497, loss:17.26938819745534\n",
      "Epoch:756, w1:95.07339333915351, w2:154.5581950123553, bias:-753.5593913927497, loss:17.26938819745534\n",
      "Epoch:757, w1:95.19862061188078, w2:154.76274046690077, bias:-754.5593913927497, loss:17.26938819745534\n",
      "Epoch:758, w1:95.32384788460806, w2:154.96728592144623, bias:-755.5593913927497, loss:17.26938819745534\n",
      "Epoch:759, w1:95.44907515733533, w2:155.1718313759917, bias:-756.5593913927497, loss:17.26938819745534\n",
      "Epoch:760, w1:95.5743024300626, w2:155.37637683053717, bias:-757.5593913927497, loss:17.26938819745534\n",
      "Epoch:761, w1:95.69952970278987, w2:155.58092228508264, bias:-758.5593913927497, loss:17.26938819745534\n",
      "Epoch:762, w1:95.82475697551715, w2:155.7854677396281, bias:-759.5593913927497, loss:17.26938819745534\n",
      "Epoch:763, w1:95.94998424824442, w2:155.99001319417357, bias:-760.5593913927497, loss:17.26938819745534\n",
      "Epoch:764, w1:96.07521152097169, w2:156.19455864871904, bias:-761.5593913927497, loss:17.26938819745534\n",
      "Epoch:765, w1:96.20043879369896, w2:156.3991041032645, bias:-762.5593913927497, loss:17.26938819745534\n",
      "Epoch:766, w1:96.32566606642624, w2:156.60364955780997, bias:-763.5593913927497, loss:17.26938819745534\n",
      "Epoch:767, w1:96.45089333915351, w2:156.80819501235544, bias:-764.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:768, w1:96.57612061188078, w2:157.0127404669009, bias:-765.5593913927497, loss:17.26938819745534\n",
      "Epoch:769, w1:96.70134788460805, w2:157.21728592144638, bias:-766.5593913927497, loss:17.26938819745534\n",
      "Epoch:770, w1:96.82657515733533, w2:157.42183137599184, bias:-767.5593913927497, loss:17.26938819745534\n",
      "Epoch:771, w1:96.9518024300626, w2:157.6263768305373, bias:-768.5593913927497, loss:17.26938819745534\n",
      "Epoch:772, w1:97.07702970278987, w2:157.83092228508278, bias:-769.5593913927497, loss:17.26938819745534\n",
      "Epoch:773, w1:97.20225697551714, w2:158.03546773962825, bias:-770.5593913927497, loss:17.26938819745534\n",
      "Epoch:774, w1:97.32748424824442, w2:158.2400131941737, bias:-771.5593913927497, loss:17.26938819745534\n",
      "Epoch:775, w1:97.45271152097169, w2:158.44455864871918, bias:-772.5593913927497, loss:17.26938819745534\n",
      "Epoch:776, w1:97.57793879369896, w2:158.64910410326465, bias:-773.5593913927497, loss:17.26938819745534\n",
      "Epoch:777, w1:97.70316606642623, w2:158.85364955781012, bias:-774.5593913927497, loss:17.26938819745534\n",
      "Epoch:778, w1:97.82839333915351, w2:159.05819501235558, bias:-775.5593913927497, loss:17.26938819745534\n",
      "Epoch:779, w1:97.95362061188078, w2:159.26274046690105, bias:-776.5593913927497, loss:17.26938819745534\n",
      "Epoch:780, w1:98.07884788460805, w2:159.46728592144652, bias:-777.5593913927497, loss:17.26938819745534\n",
      "Epoch:781, w1:98.20407515733532, w2:159.67183137599199, bias:-778.5593913927497, loss:17.26938819745534\n",
      "Epoch:782, w1:98.3293024300626, w2:159.87637683053745, bias:-779.5593913927497, loss:17.26938819745534\n",
      "Epoch:783, w1:98.45452970278987, w2:160.08092228508292, bias:-780.5593913927497, loss:17.26938819745534\n",
      "Epoch:784, w1:98.57975697551714, w2:160.2854677396284, bias:-781.5593913927497, loss:17.26938819745534\n",
      "Epoch:785, w1:98.70498424824441, w2:160.49001319417386, bias:-782.5593913927497, loss:17.26938819745534\n",
      "Epoch:786, w1:98.83021152097169, w2:160.69455864871932, bias:-783.5593913927497, loss:17.26938819745534\n",
      "Epoch:787, w1:98.95543879369896, w2:160.8991041032648, bias:-784.5593913927497, loss:17.26938819745534\n",
      "Epoch:788, w1:99.08066606642623, w2:161.10364955781026, bias:-785.5593913927497, loss:17.26938819745534\n",
      "Epoch:789, w1:99.2058933391535, w2:161.30819501235572, bias:-786.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:790, w1:99.33112061188078, w2:161.5127404669012, bias:-787.5593913927497, loss:17.26938819745534\n",
      "Epoch:791, w1:99.45634788460805, w2:161.71728592144666, bias:-788.5593913927497, loss:17.26938819745534\n",
      "Epoch:792, w1:99.58157515733532, w2:161.92183137599213, bias:-789.5593913927497, loss:17.26938819745534\n",
      "Epoch:793, w1:99.7068024300626, w2:162.1263768305376, bias:-790.5593913927497, loss:17.26938819745534\n",
      "Epoch:794, w1:99.83202970278987, w2:162.33092228508306, bias:-791.5593913927497, loss:17.26938819745534\n",
      "Epoch:795, w1:99.95725697551714, w2:162.53546773962853, bias:-792.5593913927497, loss:17.26938819745534\n",
      "Epoch:796, w1:100.08248424824441, w2:162.740013194174, bias:-793.5593913927497, loss:17.26938819745534\n",
      "Epoch:797, w1:100.20771152097169, w2:162.94455864871946, bias:-794.5593913927497, loss:17.26938819745534\n",
      "Epoch:798, w1:100.33293879369896, w2:163.14910410326493, bias:-795.5593913927497, loss:17.26938819745534\n",
      "Epoch:799, w1:100.45816606642623, w2:163.3536495578104, bias:-796.5593913927497, loss:17.26938819745534\n",
      "Epoch:800, w1:100.5833933391535, w2:163.55819501235587, bias:-797.5593913927497, loss:17.26938819745534\n",
      "Epoch:801, w1:100.70862061188078, w2:163.76274046690133, bias:-798.5593913927497, loss:17.26938819745534\n",
      "Epoch:802, w1:100.83384788460805, w2:163.9672859214468, bias:-799.5593913927497, loss:17.26938819745534\n",
      "Epoch:803, w1:100.95907515733532, w2:164.17183137599227, bias:-800.5593913927497, loss:17.26938819745534\n",
      "Epoch:804, w1:101.08430243006259, w2:164.37637683053774, bias:-801.5593913927497, loss:17.26938819745534\n",
      "Epoch:805, w1:101.20952970278987, w2:164.5809222850832, bias:-802.5593913927497, loss:17.26938819745534\n",
      "Epoch:806, w1:101.33475697551714, w2:164.78546773962867, bias:-803.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:807, w1:101.45998424824441, w2:164.99001319417414, bias:-804.5593913927497, loss:17.26938819745534\n",
      "Epoch:808, w1:101.58521152097168, w2:165.1945586487196, bias:-805.5593913927497, loss:17.26938819745534\n",
      "Epoch:809, w1:101.71043879369896, w2:165.39910410326507, bias:-806.5593913927497, loss:17.26938819745534\n",
      "Epoch:810, w1:101.83566606642623, w2:165.60364955781054, bias:-807.5593913927497, loss:17.26938819745534\n",
      "Epoch:811, w1:101.9608933391535, w2:165.808195012356, bias:-808.5593913927497, loss:17.26938819745534\n",
      "Epoch:812, w1:102.08612061188077, w2:166.01274046690148, bias:-809.5593913927497, loss:17.26938819745534\n",
      "Epoch:813, w1:102.21134788460805, w2:166.21728592144694, bias:-810.5593913927497, loss:17.26938819745534\n",
      "Epoch:814, w1:102.33657515733532, w2:166.4218313759924, bias:-811.5593913927497, loss:17.26938819745534\n",
      "Epoch:815, w1:102.46180243006259, w2:166.62637683053788, bias:-812.5593913927497, loss:17.26938819745534\n",
      "Epoch:816, w1:102.58702970278986, w2:166.83092228508335, bias:-813.5593913927497, loss:17.26938819745534\n",
      "Epoch:817, w1:102.71225697551714, w2:167.0354677396288, bias:-814.5593913927497, loss:17.26938819745534\n",
      "Epoch:818, w1:102.83748424824441, w2:167.24001319417428, bias:-815.5593913927497, loss:17.26938819745534\n",
      "Epoch:819, w1:102.96271152097168, w2:167.44455864871975, bias:-816.5593913927497, loss:17.26938819745534\n",
      "Epoch:820, w1:103.08793879369895, w2:167.64910410326522, bias:-817.5593913927497, loss:17.26938819745534\n",
      "Epoch:821, w1:103.21316606642623, w2:167.85364955781068, bias:-818.5593913927497, loss:17.26938819745534\n",
      "Epoch:822, w1:103.3383933391535, w2:168.05819501235615, bias:-819.5593913927497, loss:17.26938819745534\n",
      "Epoch:823, w1:103.46362061188077, w2:168.26274046690162, bias:-820.5593913927497, loss:17.26938819745534\n",
      "Epoch:824, w1:103.58884788460804, w2:168.4672859214471, bias:-821.5593913927497, loss:17.26938819745534\n",
      "Epoch:825, w1:103.71407515733532, w2:168.67183137599255, bias:-822.5593913927497, loss:17.26938819745534\n",
      "Epoch:826, w1:103.83930243006259, w2:168.87637683053802, bias:-823.5593913927497, loss:17.26938819745534\n",
      "Epoch:827, w1:103.96452970278986, w2:169.0809222850835, bias:-824.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:828, w1:104.08975697551713, w2:169.28546773962896, bias:-825.5593913927497, loss:17.26938819745534\n",
      "Epoch:829, w1:104.2149842482444, w2:169.49001319417442, bias:-826.5593913927497, loss:17.26938819745534\n",
      "Epoch:830, w1:104.34021152097168, w2:169.6945586487199, bias:-827.5593913927497, loss:17.26938819745534\n",
      "Epoch:831, w1:104.46543879369895, w2:169.89910410326536, bias:-828.5593913927497, loss:17.26938819745534\n",
      "Epoch:832, w1:104.59066606642622, w2:170.10364955781083, bias:-829.5593913927497, loss:17.26938819745534\n",
      "Epoch:833, w1:104.7158933391535, w2:170.3081950123563, bias:-830.5593913927497, loss:17.26938819745534\n",
      "Epoch:834, w1:104.84112061188077, w2:170.51274046690176, bias:-831.5593913927497, loss:17.26938819745534\n",
      "Epoch:835, w1:104.96634788460804, w2:170.71728592144723, bias:-832.5593913927497, loss:17.26938819745534\n",
      "Epoch:836, w1:105.09157515733531, w2:170.9218313759927, bias:-833.5593913927497, loss:17.26938819745534\n",
      "Epoch:837, w1:105.21680243006259, w2:171.12637683053816, bias:-834.5593913927497, loss:17.26938819745534\n",
      "Epoch:838, w1:105.34202970278986, w2:171.33092228508363, bias:-835.5593913927497, loss:17.26938819745534\n",
      "Epoch:839, w1:105.46725697551713, w2:171.5354677396291, bias:-836.5593913927497, loss:17.26938819745534\n",
      "Epoch:840, w1:105.5924842482444, w2:171.74001319417457, bias:-837.5593913927497, loss:17.26938819745534\n",
      "Epoch:841, w1:105.71771152097168, w2:171.94455864872003, bias:-838.5593913927497, loss:17.26938819745534\n",
      "Epoch:842, w1:105.84293879369895, w2:172.1491041032655, bias:-839.5593913927497, loss:17.26938819745534\n",
      "Epoch:843, w1:105.96816606642622, w2:172.35364955781097, bias:-840.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:844, w1:106.0933933391535, w2:172.55819501235644, bias:-841.5593913927497, loss:17.26938819745534\n",
      "Epoch:845, w1:106.21862061188077, w2:172.7627404669019, bias:-842.5593913927497, loss:17.26938819745534\n",
      "Epoch:846, w1:106.34384788460804, w2:172.96728592144737, bias:-843.5593913927497, loss:17.26938819745534\n",
      "Epoch:847, w1:106.46907515733531, w2:173.17183137599284, bias:-844.5593913927497, loss:17.26938819745534\n",
      "Epoch:848, w1:106.59430243006258, w2:173.3763768305383, bias:-845.5593913927497, loss:17.26938819745534\n",
      "Epoch:849, w1:106.71952970278986, w2:173.58092228508377, bias:-846.5593913927497, loss:17.26938819745534\n",
      "Epoch:850, w1:106.84475697551713, w2:173.78546773962924, bias:-847.5593913927497, loss:17.26938819745534\n",
      "Epoch:851, w1:106.9699842482444, w2:173.9900131941747, bias:-848.5593913927497, loss:17.26938819745534\n",
      "Epoch:852, w1:107.09521152097167, w2:174.19455864872018, bias:-849.5593913927497, loss:17.26938819745534\n",
      "Epoch:853, w1:107.22043879369895, w2:174.39910410326564, bias:-850.5593913927497, loss:17.26938819745534\n",
      "Epoch:854, w1:107.34566606642622, w2:174.6036495578111, bias:-851.5593913927497, loss:17.26938819745534\n",
      "Epoch:855, w1:107.47089333915349, w2:174.80819501235658, bias:-852.5593913927497, loss:17.26938819745534\n",
      "Epoch:856, w1:107.59612061188076, w2:175.01274046690205, bias:-853.5593913927497, loss:17.26938819745534\n",
      "Epoch:857, w1:107.72134788460804, w2:175.2172859214475, bias:-854.5593913927497, loss:17.26938819745534\n",
      "Epoch:858, w1:107.84657515733531, w2:175.42183137599298, bias:-855.5593913927497, loss:17.26938819745534\n",
      "Epoch:859, w1:107.97180243006258, w2:175.62637683053845, bias:-856.5593913927497, loss:17.26938819745534\n",
      "Epoch:860, w1:108.09702970278985, w2:175.83092228508391, bias:-857.5593913927497, loss:17.26938819745534\n",
      "Epoch:861, w1:108.22225697551713, w2:176.03546773962938, bias:-858.5593913927497, loss:17.26938819745534\n",
      "Epoch:862, w1:108.3474842482444, w2:176.24001319417485, bias:-859.5593913927497, loss:17.26938819745534\n",
      "Epoch:863, w1:108.47271152097167, w2:176.44455864872032, bias:-860.5593913927497, loss:17.26938819745534\n",
      "Epoch:864, w1:108.59793879369894, w2:176.64910410326578, bias:-861.5593913927497, loss:17.26938819745534\n",
      "Epoch:865, w1:108.72316606642622, w2:176.85364955781125, bias:-862.5593913927497, loss:17.26938819745534\n",
      "Epoch:866, w1:108.84839333915349, w2:177.05819501235672, bias:-863.5593913927497, loss:17.26938819745534\n",
      "Epoch:867, w1:108.97362061188076, w2:177.2627404669022, bias:-864.5593913927497, loss:17.26938819745534\n",
      "Epoch:868, w1:109.09884788460803, w2:177.46728592144765, bias:-865.5593913927497, loss:17.26938819745534\n",
      "Epoch:869, w1:109.2240751573353, w2:177.67183137599312, bias:-866.5593913927497, loss:17.26938819745534\n",
      "Epoch:870, w1:109.34930243006258, w2:177.8763768305386, bias:-867.5593913927497, loss:17.26938819745534\n",
      "Epoch:871, w1:109.47452970278985, w2:178.08092228508406, bias:-868.5593913927497, loss:17.26938819745534\n",
      "Epoch:872, w1:109.59975697551712, w2:178.28546773962952, bias:-869.5593913927497, loss:17.26938819745534\n",
      "Epoch:873, w1:109.7249842482444, w2:178.490013194175, bias:-870.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:874, w1:109.85021152097167, w2:178.69455864872046, bias:-871.5593913927497, loss:17.26938819745534\n",
      "Epoch:875, w1:109.97543879369894, w2:178.89910410326593, bias:-872.5593913927497, loss:17.26938819745534\n",
      "Epoch:876, w1:110.10066606642621, w2:179.1036495578114, bias:-873.5593913927497, loss:17.26938819745534\n",
      "Epoch:877, w1:110.22589333915349, w2:179.30819501235686, bias:-874.5593913927497, loss:17.26938819745534\n",
      "Epoch:878, w1:110.35112061188076, w2:179.51274046690233, bias:-875.5593913927497, loss:17.26938819745534\n",
      "Epoch:879, w1:110.47634788460803, w2:179.7172859214478, bias:-876.5593913927497, loss:17.26938819745534\n",
      "Epoch:880, w1:110.6015751573353, w2:179.92183137599326, bias:-877.5593913927497, loss:17.26938819745534\n",
      "Epoch:881, w1:110.72680243006258, w2:180.12637683053873, bias:-878.5593913927497, loss:17.26938819745534\n",
      "Epoch:882, w1:110.85202970278985, w2:180.3309222850842, bias:-879.5593913927497, loss:17.26938819745534\n",
      "Epoch:883, w1:110.97725697551712, w2:180.53546773962967, bias:-880.5593913927497, loss:17.26938819745534\n",
      "Epoch:884, w1:111.1024842482444, w2:180.74001319417513, bias:-881.5593913927497, loss:17.26938819745534\n",
      "Epoch:885, w1:111.22771152097167, w2:180.9445586487206, bias:-882.5593913927497, loss:17.26938819745534\n",
      "Epoch:886, w1:111.35293879369894, w2:181.14910410326607, bias:-883.5593913927497, loss:17.26938819745534\n",
      "Epoch:887, w1:111.47816606642621, w2:181.35364955781154, bias:-884.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:888, w1:111.60339333915348, w2:181.558195012357, bias:-885.5593913927497, loss:17.26938819745534\n",
      "Epoch:889, w1:111.72862061188076, w2:181.76274046690247, bias:-886.5593913927497, loss:17.26938819745534\n",
      "Epoch:890, w1:111.85384788460803, w2:181.96728592144794, bias:-887.5593913927497, loss:17.26938819745534\n",
      "Epoch:891, w1:111.9790751573353, w2:182.1718313759934, bias:-888.5593913927497, loss:17.26938819745534\n",
      "Epoch:892, w1:112.10430243006257, w2:182.37637683053887, bias:-889.5593913927497, loss:17.26938819745534\n",
      "Epoch:893, w1:112.22952970278985, w2:182.58092228508434, bias:-890.5593913927497, loss:17.26938819745534\n",
      "Epoch:894, w1:112.35475697551712, w2:182.7854677396298, bias:-891.5593913927497, loss:17.26938819745534\n",
      "Epoch:895, w1:112.47998424824439, w2:182.99001319417528, bias:-892.5593913927497, loss:17.26938819745534\n",
      "Epoch:896, w1:112.60521152097166, w2:183.19455864872074, bias:-893.5593913927497, loss:17.26938819745534\n",
      "Epoch:897, w1:112.73043879369894, w2:183.3991041032662, bias:-894.5593913927497, loss:17.26938819745534\n",
      "Epoch:898, w1:112.85566606642621, w2:183.60364955781168, bias:-895.5593913927497, loss:17.26938819745534\n",
      "Epoch:899, w1:112.98089333915348, w2:183.80819501235715, bias:-896.5593913927497, loss:17.26938819745534\n",
      "Epoch:900, w1:113.10612061188075, w2:184.0127404669026, bias:-897.5593913927497, loss:17.26938819745534\n",
      "Epoch:901, w1:113.23134788460803, w2:184.21728592144808, bias:-898.5593913927497, loss:17.26938819745534\n",
      "Epoch:902, w1:113.3565751573353, w2:184.42183137599355, bias:-899.5593913927497, loss:17.26938819745534\n",
      "Epoch:903, w1:113.48180243006257, w2:184.62637683053902, bias:-900.5593913927497, loss:17.26938819745534\n",
      "Epoch:904, w1:113.60702970278984, w2:184.83092228508448, bias:-901.5593913927497, loss:17.26938819745534\n",
      "Epoch:905, w1:113.73225697551712, w2:185.03546773962995, bias:-902.5593913927497, loss:17.26938819745534\n",
      "Epoch:906, w1:113.85748424824439, w2:185.24001319417542, bias:-903.5593913927497, loss:17.26938819745534\n",
      "Epoch:907, w1:113.98271152097166, w2:185.44455864872089, bias:-904.5593913927497, loss:17.26938819745534\n",
      "Epoch:908, w1:114.10793879369893, w2:185.64910410326635, bias:-905.5593913927497, loss:17.26938819745534\n",
      "Epoch:909, w1:114.23316606642621, w2:185.85364955781182, bias:-906.5593913927497, loss:17.26938819745534\n",
      "Epoch:910, w1:114.35839333915348, w2:186.0581950123573, bias:-907.5593913927497, loss:17.26938819745534\n",
      "Epoch:911, w1:114.48362061188075, w2:186.26274046690276, bias:-908.5593913927497, loss:17.26938819745534\n",
      "Epoch:912, w1:114.60884788460802, w2:186.46728592144822, bias:-909.5593913927497, loss:17.26938819745534\n",
      "Epoch:913, w1:114.7340751573353, w2:186.6718313759937, bias:-910.5593913927497, loss:17.26938819745534\n",
      "Epoch:914, w1:114.85930243006257, w2:186.87637683053916, bias:-911.5593913927497, loss:17.26938819745534\n",
      "Epoch:915, w1:114.98452970278984, w2:187.08092228508463, bias:-912.5593913927497, loss:17.26938819745534\n",
      "Epoch:916, w1:115.10975697551712, w2:187.2854677396301, bias:-913.5593913927497, loss:17.26938819745534\n",
      "Epoch:917, w1:115.23498424824439, w2:187.49001319417556, bias:-914.5593913927497, loss:17.26938819745534\n",
      "Epoch:918, w1:115.36021152097166, w2:187.69455864872103, bias:-915.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:919, w1:115.48543879369893, w2:187.8991041032665, bias:-916.5593913927497, loss:17.26938819745534\n",
      "Epoch:920, w1:115.6106660664262, w2:188.10364955781196, bias:-917.5593913927497, loss:17.26938819745534\n",
      "Epoch:921, w1:115.73589333915348, w2:188.30819501235743, bias:-918.5593913927497, loss:17.26938819745534\n",
      "Epoch:922, w1:115.86112061188075, w2:188.5127404669029, bias:-919.5593913927497, loss:17.26938819745534\n",
      "Epoch:923, w1:115.98634788460802, w2:188.71728592144837, bias:-920.5593913927497, loss:17.26938819745534\n",
      "Epoch:924, w1:116.1115751573353, w2:188.92183137599383, bias:-921.5593913927497, loss:17.26938819745534\n",
      "Epoch:925, w1:116.23680243006257, w2:189.1263768305393, bias:-922.5593913927497, loss:17.26938819745534\n",
      "Epoch:926, w1:116.36202970278984, w2:189.33092228508477, bias:-923.5593913927497, loss:17.26938819745534\n",
      "Epoch:927, w1:116.48725697551711, w2:189.53546773963023, bias:-924.5593913927497, loss:17.26938819745534\n",
      "Epoch:928, w1:116.61248424824439, w2:189.7400131941757, bias:-925.5593913927497, loss:17.26938819745534\n",
      "Epoch:929, w1:116.73771152097166, w2:189.94455864872117, bias:-926.5593913927497, loss:17.26938819745534\n",
      "Epoch:930, w1:116.86293879369893, w2:190.14910410326664, bias:-927.5593913927497, loss:17.26938819745534\n",
      "Epoch:931, w1:116.9881660664262, w2:190.3536495578121, bias:-928.5593913927497, loss:17.26938819745534\n",
      "Epoch:932, w1:117.11339333915348, w2:190.55819501235757, bias:-929.5593913927497, loss:17.26938819745534\n",
      "Epoch:933, w1:117.23862061188075, w2:190.76274046690304, bias:-930.5593913927497, loss:17.26938819745534\n",
      "Epoch:934, w1:117.36384788460802, w2:190.9672859214485, bias:-931.5593913927497, loss:17.26938819745534\n",
      "Epoch:935, w1:117.4890751573353, w2:191.17183137599397, bias:-932.5593913927497, loss:17.26938819745534\n",
      "Epoch:936, w1:117.61430243006257, w2:191.37637683053944, bias:-933.5593913927497, loss:17.26938819745534\n",
      "Epoch:937, w1:117.73952970278984, w2:191.5809222850849, bias:-934.5593913927497, loss:17.26938819745534\n",
      "Epoch:938, w1:117.86475697551711, w2:191.78546773963038, bias:-935.5593913927497, loss:17.26938819745534\n",
      "Epoch:939, w1:117.98998424824438, w2:191.99001319417584, bias:-936.5593913927497, loss:17.26938819745534\n",
      "Epoch:940, w1:118.11521152097166, w2:192.1945586487213, bias:-937.5593913927497, loss:17.26938819745534\n",
      "Epoch:941, w1:118.24043879369893, w2:192.39910410326678, bias:-938.5593913927497, loss:17.26938819745534\n",
      "Epoch:942, w1:118.3656660664262, w2:192.60364955781225, bias:-939.5593913927497, loss:17.26938819745534\n",
      "Epoch:943, w1:118.49089333915347, w2:192.80819501235771, bias:-940.5593913927497, loss:17.26938819745534\n",
      "Epoch:944, w1:118.61612061188075, w2:193.01274046690318, bias:-941.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:945, w1:118.74134788460802, w2:193.21728592144865, bias:-942.5593913927497, loss:17.26938819745534\n",
      "Epoch:946, w1:118.86657515733529, w2:193.42183137599412, bias:-943.5593913927497, loss:17.26938819745534\n",
      "Epoch:947, w1:118.99180243006256, w2:193.62637683053958, bias:-944.5593913927497, loss:17.26938819745534\n",
      "Epoch:948, w1:119.11702970278984, w2:193.83092228508505, bias:-945.5593913927497, loss:17.26938819745534\n",
      "Epoch:949, w1:119.24225697551711, w2:194.03546773963052, bias:-946.5593913927497, loss:17.26938819745534\n",
      "Epoch:950, w1:119.36748424824438, w2:194.240013194176, bias:-947.5593913927497, loss:17.26938819745534\n",
      "Epoch:951, w1:119.49271152097165, w2:194.44455864872145, bias:-948.5593913927497, loss:17.26938819745534\n",
      "Epoch:952, w1:119.61793879369893, w2:194.64910410326692, bias:-949.5593913927497, loss:17.26938819745534\n",
      "Epoch:953, w1:119.7431660664262, w2:194.8536495578124, bias:-950.5593913927497, loss:17.26938819745534\n",
      "Epoch:954, w1:119.86839333915347, w2:195.05819501235786, bias:-951.5593913927497, loss:17.26938819745534\n",
      "Epoch:955, w1:119.99362061188074, w2:195.26274046690332, bias:-952.5593913927497, loss:17.26938819745534\n",
      "Epoch:956, w1:120.11884788460802, w2:195.4672859214488, bias:-953.5593913927497, loss:17.26938819745534\n",
      "Epoch:957, w1:120.24407515733529, w2:195.67183137599426, bias:-954.5593913927497, loss:17.26938819745534\n",
      "Epoch:958, w1:120.36930243006256, w2:195.87637683053973, bias:-955.5593913927497, loss:17.26938819745534\n",
      "Epoch:959, w1:120.49452970278983, w2:196.0809222850852, bias:-956.5593913927497, loss:17.26938819745534\n",
      "Epoch:960, w1:120.6197569755171, w2:196.28546773963066, bias:-957.5593913927497, loss:17.26938819745534\n",
      "Epoch:961, w1:120.74498424824438, w2:196.49001319417613, bias:-958.5593913927497, loss:17.26938819745534\n",
      "Epoch:962, w1:120.87021152097165, w2:196.6945586487216, bias:-959.5593913927497, loss:17.26938819745534\n",
      "Epoch:963, w1:120.99543879369892, w2:196.89910410326706, bias:-960.5593913927497, loss:17.26938819745534\n",
      "Epoch:964, w1:121.1206660664262, w2:197.10364955781253, bias:-961.5593913927497, loss:17.26938819745534\n",
      "Epoch:965, w1:121.24589333915347, w2:197.308195012358, bias:-962.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:966, w1:121.37112061188074, w2:197.51274046690347, bias:-963.5593913927497, loss:17.26938819745534\n",
      "Epoch:967, w1:121.49634788460801, w2:197.71728592144893, bias:-964.5593913927497, loss:17.26938819745534\n",
      "Epoch:968, w1:121.62157515733529, w2:197.9218313759944, bias:-965.5593913927497, loss:17.26938819745534\n",
      "Epoch:969, w1:121.74680243006256, w2:198.12637683053987, bias:-966.5593913927497, loss:17.26938819745534\n",
      "Epoch:970, w1:121.87202970278983, w2:198.33092228508534, bias:-967.5593913927497, loss:17.26938819745534\n",
      "Epoch:971, w1:121.9972569755171, w2:198.5354677396308, bias:-968.5593913927497, loss:17.26938819745534\n",
      "Epoch:972, w1:122.12248424824438, w2:198.74001319417627, bias:-969.5593913927497, loss:17.26938819745534\n",
      "Epoch:973, w1:122.24771152097165, w2:198.94455864872174, bias:-970.5593913927497, loss:17.26938819745534\n",
      "Epoch:974, w1:122.37293879369892, w2:199.1491041032672, bias:-971.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:975, w1:122.4981660664262, w2:199.35364955781267, bias:-972.5593913927497, loss:17.26938819745534\n",
      "Epoch:976, w1:122.62339333915347, w2:199.55819501235814, bias:-973.5593913927497, loss:17.26938819745534\n",
      "Epoch:977, w1:122.74862061188074, w2:199.7627404669036, bias:-974.5593913927497, loss:17.26938819745534\n",
      "Epoch:978, w1:122.87384788460801, w2:199.96728592144908, bias:-975.5593913927497, loss:17.26938819745534\n",
      "Epoch:979, w1:122.99907515733528, w2:200.17183137599454, bias:-976.5593913927497, loss:17.26938819745534\n",
      "Epoch:980, w1:123.12430243006256, w2:200.37637683054, bias:-977.5593913927497, loss:17.26938819745534\n",
      "Epoch:981, w1:123.24952970278983, w2:200.58092228508548, bias:-978.5593913927497, loss:17.26938819745534\n",
      "Epoch:982, w1:123.3747569755171, w2:200.78546773963095, bias:-979.5593913927497, loss:17.26938819745534\n",
      "Epoch:983, w1:123.49998424824437, w2:200.9900131941764, bias:-980.5593913927497, loss:17.26938819745534\n",
      "Epoch:984, w1:123.62521152097165, w2:201.19455864872188, bias:-981.5593913927497, loss:17.26938819745534\n",
      "Epoch:985, w1:123.75043879369892, w2:201.39910410326735, bias:-982.5593913927497, loss:17.26938819745534\n",
      "Epoch:986, w1:123.87566606642619, w2:201.60364955781282, bias:-983.5593913927497, loss:17.26938819745534\n",
      "Epoch:987, w1:124.00089333915346, w2:201.80819501235828, bias:-984.5593913927497, loss:17.26938819745534\n",
      "Epoch:988, w1:124.12612061188074, w2:202.01274046690375, bias:-985.5593913927497, loss:17.26938819745534\n",
      "Epoch:989, w1:124.25134788460801, w2:202.21728592144922, bias:-986.5593913927497, loss:17.26938819745534\n",
      "Epoch:990, w1:124.37657515733528, w2:202.42183137599469, bias:-987.5593913927497, loss:17.26938819745534\n",
      "Epoch:991, w1:124.50180243006255, w2:202.62637683054015, bias:-988.5593913927497, loss:17.26938819745534\n",
      "Epoch:992, w1:124.62702970278983, w2:202.83092228508562, bias:-989.5593913927497, loss:17.26938819745534\n",
      "Epoch:993, w1:124.7522569755171, w2:203.0354677396311, bias:-990.5593913927497, loss:17.26938819745534\n",
      "Epoch:994, w1:124.87748424824437, w2:203.24001319417656, bias:-991.5593913927497, loss:17.26938819745534\n",
      "Epoch:995, w1:125.00271152097164, w2:203.44455864872202, bias:-992.5593913927497, loss:17.26938819745534\n",
      "Epoch:996, w1:125.12793879369892, w2:203.6491041032675, bias:-993.5593913927497, loss:17.26938819745534\n",
      "Epoch:997, w1:125.25316606642619, w2:203.85364955781296, bias:-994.5593913927497, loss:17.26938819745534\n",
      "Epoch:998, w1:125.37839333915346, w2:204.05819501235842, bias:-995.5593913927497, loss:17.26938819745534\n",
      "Epoch:999, w1:125.50362061188073, w2:204.2627404669039, bias:-996.5593913927497, loss:17.26938819745534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\soura\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125.50362061188073, 204.2627404669039, -996.5593913927497)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(x_train_scaled['age'], x_train_scaled['affordibility'],y_train,1000,0.5321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57061f3-eb1f-45f7-9494-3b7b2107eac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
